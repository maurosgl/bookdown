[["index.html", "Series de Tiempo - Predicción de Precios de Frutas y Verduras en Nepal Capítulo 1 Introducción", " Series de Tiempo - Predicción de Precios de Frutas y Verduras en Nepal Grupo 2 2025-11-11 Capítulo 1 Introducción Time Series Price Vegetables and Fruits El conjunto de datos “Time Series Price Vegetables and Fruits” contiene información oficial sobre los precios diarios de las principales frutas y verduras en Nepal entre 2013 y 2021 de una fuente oficial del gobierno (Kalimati), compilada en un repositorio público Kaggle. Commodity: Nombre de las frutas o vegetales Date: Fecha en formato año - mes – día Unit: Unidad de medida (Kg) Minimum: Precio mínimo registrado de venta del día Maximum: Precio máximo registrado de venta del día Average: Precio promedio de venta del día Analizar y predecir el precio de productos agrícolas es fundamental para poder tomar decisiones informadas, asignar los recursos de una manera óptima y contribuir al crecimiento económico del agro. Por la dinámica de los precios en frutas y verduras, que se encuentra condicionada por temporadas de cosecha, factores climáticos y la relación entre oferta y demanda, resulta complejo proyectar precios de manera certera. Con modelos tradicionales de análisis, captar patrones puede ser difícil; sin embargo, esta limitación puede superarse mediante técnicas de machine learning aplicadas a series de tiempo. La selección del dataset se debe al carácter temporal y a la granularidad de los datos, lo que facilita hallar tendencias y estacionalidades en los precios, emplear datos históricos para predecir precios futuros, así como detectar patrones inusuales o anomalías en los datos. Otro valor importante que puede lograrse a través del análisis del conjunto de datos es el desarrollo de estrategias de precios basadas en los patrones hallados. "],["eda-y-análisis-de-series-de-tiempo.html", "Capítulo 2 EDA y Análisis de Series de tiempo 2.1 Analisis de series de tiempo", " Capítulo 2 EDA y Análisis de Series de tiempo 2.0.1 Cargue de Datos # Librerias (base originales + necesarias) library(readr) library(dplyr) library(lubridate) library(ggplot2) library(forecast) library(tseries) library(here) # rutas reproducibles library(tidyr) # regularizar fechas (complete) library(slider) # promedios moviles Realizaremos nuestro analisis con un conjunto de datos de precios agrícolas proveniente del mercado de Kalimati (Nepal). Este dataset incluye información diaria sobre productos agrícolas, sus precios mínimos, máximos y promedio. A partir de estos datos se realizará un análisis exploratorio y un estudio de comportamiento temporal de los precios. csv_file &lt;- &quot;C:/Users/Steba/OneDrive/Escritorio/kalimati_tarkari_dataset (2).csv&quot; # Leer datos data_raw &lt;- readr::read_csv(csv_file, show_col_types = FALSE) # Estandarizar nombres a snake para facilitar mapeo nms &lt;- tolower(gsub(&quot;[^a-zA-Z0-9]+&quot;, &quot;_&quot;, names(data_raw))) # Intentar mapear columnas canonicas (Commodity / Date / Minimum / Maximum / Average) df &lt;- data_raw names(df) &lt;- nms # Mapeo flexible (case-insensitive) pick_first &lt;- function(cands) { hit &lt;- intersect(cands, names(df)) if (length(hit) == 0) return(NA_character_) else return(hit[1]) } col_commodity &lt;- pick_first(c(&quot;commodity&quot;,&quot;item&quot;,&quot;product&quot;,&quot;variety&quot;,&quot;name&quot;)) col_date &lt;- pick_first(c(&quot;date&quot;,&quot;fecha&quot;,&quot;day&quot;)) col_min &lt;- pick_first(c(&quot;minimum&quot;,&quot;min&quot;,&quot;min_price&quot;,&quot;price_min&quot;)) col_max &lt;- pick_first(c(&quot;maximum&quot;,&quot;max&quot;,&quot;max_price&quot;,&quot;price_max&quot;)) col_avg &lt;- pick_first(c(&quot;average&quot;,&quot;avg&quot;,&quot;avg_price&quot;,&quot;price_avg&quot;,&quot;mean_price&quot;)) req &lt;- c(col_commodity, col_date, col_min, col_max, col_avg) if (any(is.na(req))) { stop(&quot;No fue posible mapear columnas clave (commodity/date/min/max/average). Revisa nombres del CSV: &quot;, paste(names(df), collapse = &quot;, &quot;)) } data &lt;- df %&gt;% transmute( Commodity = .data[[col_commodity]], Date = as.Date(.data[[col_date]]), Unit = NA_character_, # si no existe, queda NA (no se usa en el analisis) Minimum = as.numeric(.data[[col_min]]), Maximum = as.numeric(.data[[col_max]]), Average = as.numeric(.data[[col_avg]]) ) # Chequeos basicos stopifnot(inherits(data$Date, &quot;Date&quot;)) 2.0.2 Primera Visualización de los datos # Vista previa y estructura head(data) ## # A tibble: 6 × 6 ## Commodity Date Unit Minimum Maximum Average ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Tomato Big(Nepali) 2013-06-16 &lt;NA&gt; 35 40 37.5 ## 2 Tomato Small(Local) 2013-06-16 &lt;NA&gt; 26 32 29 ## 3 Potato Red 2013-06-16 &lt;NA&gt; 20 21 20.5 ## 4 Potato White 2013-06-16 &lt;NA&gt; 15 16 15.5 ## 5 Onion Dry (Indian) 2013-06-16 &lt;NA&gt; 28 30 29 ## 6 Carrot(Local) 2013-06-16 &lt;NA&gt; 30 35 32.5 str(data) ## tibble [197,161 × 6] (S3: tbl_df/tbl/data.frame) ## $ Commodity: chr [1:197161] &quot;Tomato Big(Nepali)&quot; &quot;Tomato Small(Local)&quot; &quot;Potato Red&quot; &quot;Potato White&quot; ... ## $ Date : Date[1:197161], format: &quot;2013-06-16&quot; &quot;2013-06-16&quot; ... ## $ Unit : chr [1:197161] NA NA NA NA ... ## $ Minimum : num [1:197161] 35 26 20 15 28 30 6 30 35 25 ... ## $ Maximum : num [1:197161] 40 32 21 16 30 35 10 35 40 30 ... ## $ Average : num [1:197161] 37.5 29 20.5 15.5 29 32.5 8 32.5 37.5 27.5 ... summary(data) ## Commodity Date Unit Minimum ## Length:197161 Min. :2013-06-16 Length:197161 Min. : 1.00 ## Class :character 1st Qu.:2015-08-24 Class :character 1st Qu.: 40.00 ## Mode :character Median :2017-08-03 Mode :character Median : 60.00 ## Mean :2017-08-09 Mean : 85.42 ## 3rd Qu.:2019-08-27 3rd Qu.: 100.00 ## Max. :2021-05-13 Max. :1800.00 ## Maximum Average ## Min. : 6.00 Min. : 5.00 ## 1st Qu.: 45.00 1st Qu.: 42.50 ## Median : 70.00 Median : 65.00 ## Mean : 94.16 Mean : 89.79 ## 3rd Qu.: 110.00 3rd Qu.: 105.00 ## Max. :2000.00 Max. :1900.00 2.0.3 Datos faltantes y duplicados # NAs y duplicados generales sum(is.na(data)) ## [1] 197161 sum(duplicated(data)) ## [1] 0 2.0.4 Análisis Univariado #analisis univariado ggplot(data, aes(x = Average)) + geom_histogram(binwidth = 5, fill = &quot;blue&quot;, color = &quot;black&quot;, alpha = 0.7) + labs(title = &quot;Distribucion de Precios Promedio&quot;, x = &quot;Precio Promedio&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() data %&gt;% summarise( Mean = mean(Average, na.rm = TRUE), Median = median(Average, na.rm = TRUE), SD = sd(Average, na.rm = TRUE), Min = min(Average, na.rm = TRUE), Max = max(Average, na.rm = TRUE) ) ## # A tibble: 1 × 5 ## Mean Median SD Min Max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 89.8 65 79.6 5 1900 2.0.5 Análisis Bivariado #analisis bivariado ggplot(data, aes(x = Minimum, y = Maximum)) + geom_point(alpha = 0.5) + labs(title = &quot;Relacion entre Precio Minimo y Maximo&quot;, x = &quot;Precio Minimo&quot;, y = &quot;Precio Maximo&quot;) + theme_minimal() 2.0.6 Correlación de los datos cor(data$Minimum, data$Maximum, use = &quot;complete.obs&quot;) ## [1] 0.9950614 2.1 Analisis de series de tiempo if (&quot;Potato Red&quot; %in% unique(data$Commodity)) { target_item &lt;- &quot;Potato Red&quot; } else { target_item &lt;- data %&gt;% count(Commodity, sort = TRUE) %&gt;% slice(1) %&gt;% pull(Commodity) } target_item ## [1] &quot;Potato Red&quot; # Filtrar y regularizar serie diaria potatored &lt;- data %&gt;% filter(Commodity == target_item) %&gt;% select(Date, Average) %&gt;% group_by(Date) %&gt;% summarise(Average = mean(Average), .groups = &quot;drop&quot;) %&gt;% complete(Date = seq(min(Date, na.rm = TRUE), max(Date, na.rm = TRUE), by = &quot;day&quot;)) %&gt;% arrange(Date) # Construir objeto ts (diario, 365) pot_ts &lt;- ts( potatored$Average, start = c(lubridate::year(min(potatored$Date, na.rm = TRUE)), lubridate::yday(min(potatored$Date, na.rm = TRUE))), frequency = 365 ) 2.1.1 Serie basica y ACF autoplot(pot_ts) + labs(title = &quot;Serie de tiempo: precio promedio&quot;, y = &quot;Precio promedio&quot;) + theme_minimal() ggAcf(pot_ts) + labs(title = &quot;ACF del precio promedio (diario)&quot;) 2.1.2 Promedios moviles (evidencia de suavizado) pot_ma &lt;- potatored %&gt;% mutate( ma7 = slide_dbl(Average, mean, .before = 6, .complete = TRUE), ma30 = slide_dbl(Average, mean, .before = 29, .complete = TRUE) ) ggplot(pot_ma, aes(Date, Average)) + geom_line(linewidth = 0.5, alpha = 0.6) + geom_line(aes(y = ma7), linewidth = 0.8) + geom_line(aes(y = ma30), linewidth = 0.9) + labs(title = &quot;Serie y promedios moviles (7 y 30 dias)&quot;, x = &quot;Fecha&quot;, y = &quot;Precio promedio&quot;) + theme_minimal() 2.1.3 Rezagos (lags) y dependencia temporal pot_lags &lt;- potatored %&gt;% mutate( lag1 = dplyr::lag(Average, 1), lag7 = dplyr::lag(Average, 7), lag30 = dplyr::lag(Average, 30) ) # Scatter y_t vs y_{t-1} ggplot(pot_lags, aes(lag1, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 1 (y_t vs y_{t-1})&quot;, x = &quot;y_{t-1}&quot;, y = &quot;y_t&quot;) # Scatter y_t vs y_{t-7} ggplot(pot_lags, aes(lag7, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 7 (aprox. semanal)&quot;, x = &quot;y_{t-7}&quot;, y = &quot;y_t&quot;) # ACF/PACF (serie regularizada) ggAcf(pot_ts) + labs(title = &quot;ACF precio promedio (diario)&quot;) ggPacf(pot_ts) + labs(title = &quot;PACF precio promedio (diario)&quot;) 2.1.4 Estacionalidad (descomposicion STL) fit_stl &lt;- stl(na.interp(pot_ts), s.window = &quot;periodic&quot;, robust = TRUE) autoplot(fit_stl) + labs(title = &quot;STL precio promedio&quot;) El análisis de la serie temporal del precio promedio diario de Potato Red permitió evidenciar comportamientos consistentes con los fenómenos propios de los productos agrícolas de consumo masivo. En primer lugar, los gráficos de tendencia y promedios móviles muestran que los precios presentan fluctuaciones periódicas pero con una ligera tendencia creciente en el largo plazo. El promedio móvil de 7 días suaviza las variaciones diarias y deja entrever ciclos semanales asociados a la oferta en el mercado, mientras que el promedio de 30 días resalta un patrón más estructural que apunta a incrementos graduales, posiblemente relacionados con factores estacionales como la disponibilidad de cosecha o la variación de costos logísticos. El estudio de rezagos (lag 1, lag 7 y lag 30) refuerza esta observación: las gráficas de dispersión muestran una clara autocorrelación positiva, especialmente para rezagos cortos, indicando que los precios actuales dependen directamente de los valores recientes. Este comportamiento sugiere persistencia temporal: cuando los precios aumentan o disminuyen, tienden a mantener esa dirección durante varios días, lo cual es característico de mercados donde la información y las condiciones de oferta no cambian abruptamente. La función de autocorrelación (ACF) confirma esta dependencia temporal, con correlaciones significativas en los primeros rezagos que luego disminuyen de forma progresiva. Esto demuestra que la serie no sigue un comportamiento completamente aleatorio, sino que existen patrones repetitivos en el tiempo. La descomposición STL separó la serie en sus componentes de tendencia, estacionalidad y residuo. Los resultados muestran una estacionalidad marcada con ciclos anuales definidos: los precios tienden a elevarse en ciertas épocas del año y disminuir en otras, reflejando los periodos de cosecha y escasez. La tendencia general es estable con una leve inclinación al alza, mientras que los residuos mantienen una magnitud baja y no presentan patrones visibles, lo que indica que gran parte de la variabilidad del precio está explicada por la tendencia y la estacionalidad, sin presencia de choques exógenos significativos. En conjunto, estos hallazgos evidencian que la serie del precio promedio de Potato Red posee un comportamiento no estacionario, con una tendencia creciente y estacionalidad recurrente, pero sin irregularidades fuertes. El patrón identificado sugiere que los precios pueden modelarse de forma confiable mediante técnicas de suavizado exponencial o modelos ARIMA estacionales, una vez que se realicen las transformaciones necesarias para estabilizar la media y la varianza. En términos prácticos, los resultados reflejan que el mercado analizado responde a ciclos previsibles, lo cual facilita la planificación de precios, abastecimiento y estrategias de comercialización. 2.1.5 Estacionariedad y diferenciación Introducción En esta segunda parte se busca analizar si la serie de tiempo seleccionada (Potato Red) cumple con el supuesto de estacionariedad. Una serie estacionaria es aquella cuya media y varianza permanecen constantes en el tiempo. En caso de que no sea estacionaria, se aplicarán procedimientos de diferenciación # o transformación para estabilizar la tendencia y la variabilidad. # Usaremos una version &quot;limpia&quot; de la serie via interpolacion lineal base R, partimos de &#39;potatored&#39; (data.frame terminado) y/o de &#39;pot_ts&#39; (ts original) y &lt;- as.numeric(pot_ts) if (anyNA(y)) { idx_ok &lt;- which(!is.na(y)) y_interp &lt;- approx(x = idx_ok, y = y[idx_ok], xout = seq_along(y))$y } else { y_interp &lt;- y} pot_ts_clean &lt;- ts( y_interp, start = start(pot_ts), frequency = frequency(pot_ts) ) 2.1.6 Verificación de estacionariedad (ADF Test) # Prueba de raíz unitaria de Dickey-Fuller aumentada adf_result &lt;- adf.test(pot_ts_clean) adf_result ## ## Augmented Dickey-Fuller Test ## ## data: pot_ts_clean ## Dickey-Fuller = -3.0587, Lag order = 14, p-value = 0.1301 ## alternative hypothesis: stationary # al tener en el ADF inicial: p = 0.1301 → se concluye que es no estacionaria al nive, por lo cual procedemos con transformacion y diferenciacion en escalones # Serie base a usar en esta etapa y verificamos que no tenga na ni valores negativos y0 &lt;- pot_ts_clean sum(is.na(y0)) ## [1] 0 all(y0&gt;0) ## [1] TRUE y_log &lt;- log(y0) range(y0, na.rm = TRUE); range(y_log, na.rm = TRUE) # solo para verificar el cambio de escala ## [1] 15.0 113.5 ## [1] 2.708050 4.731803 adf_log &lt;- adf.test(y_log) adf_log$p.value ## [1] 0.1322035 La transformación logarítmica ayudó a homogeneizar la variabilidad, pero no eliminó la tendencia ni la dependencia temporal. La serie transformada sigue teniendo raíz unitaria, por lo que pasamos a una diferenciacion de primer orden (d=1) sobre la serie logaritmica y volvemos a probar estacionariedad. y_diff1 &lt;- diff(y_log, differences = 1) adf_diff1 &lt;- tseries::adf.test(na.omit(y_diff1)) adf_diff1$p.value ## [1] 0.01 con este resultado podemos concluir que: La serie original no era estacionaria (p = 0.1301). La serie logarítmica tampoco lo fue (p = 0.1322), aunque esa transformación ayudó a estabilizar la varianza Al aplicar una diferencia de primer orden sobre la serie logarítmica, la prueba ADF arrojó p = 0.01, es decir &lt; 0.05, por lo tanto sí es estacionaria. 2.1.7 Interpretacion Luego de aplicar la transformación logarítmica, la serie mantuvo la misma tendencia general, por lo que no se logró estacionariedad. Sin embargo, al diferenciarla una vez (d = 1), la prueba de Dickey–Fuller aumentada mostró un p-valor de 0.01, lo que indica que se rechaza la hipótesis nula de raíz unitaria. En consecuencia, la serie diferenciada es estacionaria. Este resultado implica que la tendencia determinista fue eliminada mediante la primera diferencia, estabilizando la media a lo largo del tiempo. Por otro lado, la transformación logarítmica permitió controlar la heterocedasticidad, de modo que las fluctuaciones de la serie ahora son de magnitud comparable. La combinación de ambos pasos —logaritmo y diferencia de primer orden— produce una serie adecuada para modelar mediante métodos lineales, como los modelos ARIMA o SARIMA. Visualmente, la serie diferenciada oscila alrededor de cero y las funciones de autocorrelación (ACF y PACF) se estabilizan rápidamente, lo que refuerza la evidencia de estacionariedad. "],["pronóstico-de-demanda-holtwinters.html", "Capítulo 3 Pronóstico de Demanda HoltWinters 3.1 Analisis de series de tiempo 3.2 Estacionariedad y diferenciación 3.3 Suavizamiento y Holt-Winters sobre la variable tiempo 3.4 Desarrollo metodológico y justificación de decisiones", " Capítulo 3 Pronóstico de Demanda HoltWinters Este análisis aborda el pronóstico de los precios del “Potato Red” del mercado de Kalimati. Inicia con la carga, limpieza y un análisis exploratorio (EDA) para identificar tendencias y estacionalidad. Dada la alta frecuencia de los datos diarios, la serie se agrega a un formato semanal (frecuencia 52) para permitir un modelado estable. Posteriormente, se comparan varios métodos de suavizamiento exponencial (SES, Holt, Holt-Winters Aditivo y Multiplicativo) en conjuntos de entrenamiento y prueba. Finalmente, se selecciona el modelo Holt-Winters Multiplicativo, basado en su precisión (RMSE/MAPE), para generar un pronóstico validado a 52 semanas. # Librerias (base originales + necesarias) library(readr) library(dplyr) library(lubridate) library(ggplot2) library(forecast) library(tseries) library(here) # rutas reproducibles library(tidyr) # regularizar fechas (complete) library(slider) # promedios moviles Realizaremos nuestro analisis con un conjunto de datos de precios agrícolas proveniente del mercado de Kalimati (Nepal). Este dataset incluye información diaria sobre productos agrícolas, sus precios mínimos, máximos y promedio. A partir de estos datos se realizará un análisis exploratorio y un estudio de comportamiento temporal de los precios. csv_file &lt;- &quot;C:/Users/Steba/OneDrive/Escritorio/kalimati_tarkari_dataset (2).csv&quot; # Leer datos data_raw &lt;- readr::read_csv(csv_file, show_col_types = FALSE) # Estandarizar nombres a snake para facilitar mapeo nms &lt;- tolower(gsub(&quot;[^a-zA-Z0-9]+&quot;, &quot;_&quot;, names(data_raw))) # Intentar mapear columnas canonicas (Commodity / Date / Minimum / Maximum / Average) df &lt;- data_raw names(df) &lt;- nms # Mapeo flexible (case-insensitive) pick_first &lt;- function(cands) { hit &lt;- intersect(cands, names(df)) if (length(hit) == 0) return(NA_character_) else return(hit[1]) } col_commodity &lt;- pick_first(c(&quot;commodity&quot;,&quot;item&quot;,&quot;product&quot;,&quot;variety&quot;,&quot;name&quot;)) col_date &lt;- pick_first(c(&quot;date&quot;,&quot;fecha&quot;,&quot;day&quot;)) col_min &lt;- pick_first(c(&quot;minimum&quot;,&quot;min&quot;,&quot;min_price&quot;,&quot;price_min&quot;)) col_max &lt;- pick_first(c(&quot;maximum&quot;,&quot;max&quot;,&quot;max_price&quot;,&quot;price_max&quot;)) col_avg &lt;- pick_first(c(&quot;average&quot;,&quot;avg&quot;,&quot;avg_price&quot;,&quot;price_avg&quot;,&quot;mean_price&quot;)) req &lt;- c(col_commodity, col_date, col_min, col_max, col_avg) if (any(is.na(req))) { stop(&quot;No fue posible mapear columnas clave (commodity/date/min/max/average). Revisa nombres del CSV: &quot;, paste(names(df), collapse = &quot;, &quot;)) } data &lt;- df %&gt;% transmute( Commodity = .data[[col_commodity]], Date = as.Date(.data[[col_date]]), Unit = NA_character_, # si no existe, queda NA (no se usa en el analisis) Minimum = as.numeric(.data[[col_min]]), Maximum = as.numeric(.data[[col_max]]), Average = as.numeric(.data[[col_avg]]) ) # Chequeos basicos stopifnot(inherits(data$Date, &quot;Date&quot;)) 3.1 Analisis de series de tiempo 3.1.1 Selección del item objetivo Se selecciona el producto a analizar. El código prioriza “Potato Red”, pero si no existe, selecciona el producto con más observaciones mediante (count(Commodity, sort = TRUE)) if (&quot;Potato Red&quot; %in% unique(data$Commodity)) { target_item &lt;- &quot;Potato Red&quot; } else { target_item &lt;- data %&gt;% count(Commodity, sort = TRUE) %&gt;% slice(1) %&gt;% pull(Commodity) } target_item ## [1] &quot;Potato Red&quot; Una vez se cuenta con el dataset filtrado para el item “Potato Red”, mediante broupby y summarise se asegura que sólo exista un precio promedio por día evitando conflictos con entreadas duplicadas. Mediante complete() además se regulariza la serie temporal, insertando filas con NA para los días faltantes en el rango de fechas. Además se cponstruye la Serie de tiempos diaria para evaluar el comportamiento inicialmente. # Filtrar y regularizar serie diaria potatored &lt;- data %&gt;% filter(Commodity == target_item) %&gt;% select(Date, Average) %&gt;% group_by(Date) %&gt;% summarise(Average = mean(Average), .groups = &quot;drop&quot;) %&gt;% complete(Date = seq(min(Date, na.rm = TRUE), max(Date, na.rm = TRUE), by = &quot;day&quot;)) %&gt;% arrange(Date) # Construir objeto ts (diario, 365) pot_ts &lt;- ts( potatored$Average, start = c(lubridate::year(min(potatored$Date, na.rm = TRUE)), lubridate::yday(min(potatored$Date, na.rm = TRUE))), frequency = 365 ) 3.1.2 Serie basica y ACF A continuación mediante autoplot se observa la tenedencia y la estacionalidad anual. autoplot(pot_ts) + labs(title = &quot;Serie de tiempo: precio promedio&quot;, y = &quot;Precio promedio&quot;) + theme_minimal() ggAcf(pot_ts) + labs(title = &quot;ACF del precio promedio (diario)&quot;) La función de autocorrelación (ACF) confirma esta dependencia temporal, con correlaciones significativas en los primeros rezagos que luego disminuyen de forma progresiva. Esto demuestra que la serie no sigue un comportamiento completamente aleatorio, sino que existen patrones repetitivos en el tiempo. 3.1.3 Promedios moviles (evidencia de suavizado) pot_ma &lt;- potatored %&gt;% mutate( ma7 = slide_dbl(Average, mean, .before = 6, .complete = TRUE), ma30 = slide_dbl(Average, mean, .before = 29, .complete = TRUE) ) ggplot(pot_ma, aes(Date, Average)) + geom_line(linewidth = 0.5, alpha = 0.6) + geom_line(aes(y = ma7), linewidth = 0.8) + geom_line(aes(y = ma30), linewidth = 0.9) + labs(title = &quot;Serie y promedios moviles (7 y 30 dias)&quot;, x = &quot;Fecha&quot;, y = &quot;Precio promedio&quot;) + theme_minimal() Los gráficos de tendencia y promedios móviles muestran que los precios presentan fluctuaciones periódicas pero con una ligera tendencia creciente en el largo plazo. El promedio móvil de 7 días suaviza las variaciones diarias y deja entrever ciclos semanales asociados a la oferta en el mercado, mientras que el promedio de 30 días resalta un patrón más estructural que apunta a incrementos graduales, posiblemente relacionados con factores estacionales como la disponibilidad de cosecha o la variación de costos logísticos. 3.1.4 Rezagos (lags) y dependencia temporal pot_lags &lt;- potatored %&gt;% mutate( lag1 = dplyr::lag(Average, 1), lag7 = dplyr::lag(Average, 7), lag30 = dplyr::lag(Average, 30) ) # Scatter y_t vs y_{t-1} ggplot(pot_lags, aes(lag1, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 1 (y_t vs y_{t-1})&quot;, x = &quot;y_{t-1}&quot;, y = &quot;y_t&quot;) # Scatter y_t vs y_{t-7} ggplot(pot_lags, aes(lag7, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 7 (aprox. semanal)&quot;, x = &quot;y_{t-7}&quot;, y = &quot;y_t&quot;) # ACF/PACF (serie regularizada) ggAcf(pot_ts) + labs(title = &quot;ACF precio promedio (diario)&quot;) ggPacf(pot_ts) + labs(title = &quot;PACF precio promedio (diario)&quot;) El estudio de rezagos (lag 1, lag 7 y lag 30) refuerza esta observación: las gráficas de dispersión muestran una clara autocorrelación positiva, especialmente para rezagos cortos, indicando que los precios actuales dependen directamente de los valores recientes. Este comportamiento sugiere persistencia temporal: cuando los precios aumentan o disminuyen, tienden a mantener esa dirección durante varios días, lo cual es característico de mercados donde la información y las condiciones de oferta no cambian abruptamente. 3.1.5 Estacionalidad (descomposicion STL) fit_stl &lt;- stl(na.interp(pot_ts), s.window = &quot;periodic&quot;, robust = TRUE) autoplot(fit_stl) + labs(title = &quot;STL precio promedio&quot;) La descomposición STL separó la serie en sus componentes de tendencia, estacionalidad y residuo. Los resultados muestran una estacionalidad marcada con ciclos anuales definidos: los precios tienden a elevarse en ciertas épocas del año y disminuir en otras, reflejando los periodos de cosecha y escasez. La tendencia general es estable con una leve inclinación al alza, mientras que los residuos mantienen una magnitud baja y no presentan patrones visibles, lo que indica que gran parte de la variabilidad del precio está explicada por la tendencia y la estacionalidad, sin presencia de choques exógenos significativos. 3.1.6 Análisis Conglomerado En conjunto, estos hallazgos evidencian que la serie del precio promedio de Potato Red posee un comportamiento no estacionario, con una tendencia creciente y estacionalidad recurrente, pero sin irregularidades fuertes. El patrón identificado sugiere que los precios pueden modelarse de forma confiable mediante técnicas de suavizado exponencial o modelos ARIMA estacionales, una vez que se realicen las transformaciones necesarias para estabilizar la media y la varianza. En términos prácticos, los resultados reflejan que el mercado analizado responde a ciclos previsibles, lo cual facilita la planificación de precios, abastecimiento y estrategias de comercialización. 3.2 Estacionariedad y diferenciación En esta segunda parte se busca analizar si la serie de tiempo seleccionada (Potato Red) cumple con el supuesto de estacionariedad. Una serie estacionaria es aquella cuya media y varianza permanecen constantes en el tiempo. En caso de que no sea estacionaria, se aplicarán procedimientos de diferenciación # o transformación para estabilizar la tendencia y la variabilidad. y &lt;- as.numeric(pot_ts) if (anyNA(y)) { idx_ok &lt;- which(!is.na(y)) y_interp &lt;- approx(x = idx_ok, y = y[idx_ok], xout = seq_along(y))$y } else { y_interp &lt;- y} pot_ts_clean &lt;- ts( y_interp, start = start(pot_ts), frequency = frequency(pot_ts) ) 3.2.1 Verificación de estacionariedad (ADF Test) # Prueba de raíz unitaria de Dickey-Fuller adf_result &lt;- adf.test(pot_ts_clean) adf_result ## ## Augmented Dickey-Fuller Test ## ## data: pot_ts_clean ## Dickey-Fuller = -3.0587, Lag order = 14, p-value = 0.1301 ## alternative hypothesis: stationary El p-valor es 0.13. Como p &gt; 0.05, no podemos rechazar la H_0. Esto confirma estadísticamente lo que vimos en el ACF: la serie no es estacionaria y necesita ser diferenciada. # Serie base a usar en esta etapa y verificamos que no tenga na ni valores negativos y0 &lt;- pot_ts_clean sum(is.na(y0)) ## [1] 0 all(y0&gt;0) ## [1] TRUE y_log &lt;- log(y0) range(y0, na.rm = TRUE); range(y_log, na.rm = TRUE) # solo para verificar el cambio de escala ## [1] 15.0 113.5 ## [1] 2.708050 4.731803 adf_log &lt;- adf.test(y_log) adf_log$p.value ## [1] 0.1322035 Se aplica una transformación logarítmica. Esto no corrige la tendencia, sino que ayuda a estabilizar la varianza. Es común en series de precios donde las fluctuaciones crecen a medida que el precio sube. Como era de esperar, la serie logarítmica sigue siendo no estacionaria (p=0.13). La transformación logarítmica ayudó a homogeneizar la variabilidad, pero no eliminó la tendencia ni la dependencia temporal. La serie transformada sigue teniendo raíz unitaria, por lo que pasamos a una diferenciacion de primer orden (d=1) sobre la serie logaritmica y volvemos a probar estacionariedad. y_diff1 &lt;- diff(y_log, differences = 1) adf_diff1 &lt;- tseries::adf.test(na.omit(y_diff1)) adf_diff1$p.value ## [1] 0.01 Se aplica una primera diferencia a la serie logarítmica, buscando eliminar la tendencia. Tras realizar la prueba adf nuevamente, es posible determinar que el p-valor es 0.01. Como p &lt; 0.05, rechazamos la H_0. Concluimos que la serie transformada es estacionaria. 3.2.2 Interpretacion Luego de aplicar la transformación logarítmica, la serie mantuvo la misma tendencia general, por lo que no se logró estacionariedad. Sin embargo, al diferenciarla una vez (d = 1), la prueba de Dickey–Fuller aumentada mostró un p-valor de 0.01, lo que indica que se rechaza la hipótesis nula de raíz unitaria. En consecuencia, la serie diferenciada es estacionaria. Este resultado implica que la tendencia determinista fue eliminada mediante la primera diferencia, estabilizando la media a lo largo del tiempo. Por otro lado, la transformación logarítmica permitió controlar la heterocedasticidad, de modo que las fluctuaciones de la serie ahora son de magnitud comparable. La combinación de ambos pasos —logaritmo y diferencia de primer orden— produce una serie adecuada para modelar mediante métodos lineales, como los modelos ARIMA o SARIMA. Visualmente, la serie diferenciada oscila alrededor de cero y las funciones de autocorrelación (ACF y PACF) se estabilizan rápidamente, lo que refuerza la evidencia de estacionariedad. 3.3 Suavizamiento y Holt-Winters sobre la variable tiempo y_hw &lt;- na.interp(pot_ts) freq &lt;- frequency(y_hw) length(y_hw); freq ## [1] 2889 ## [1] 365 3.3.1 Particion de entrenamiento /prueba h_test &lt;- min(365, floor(length(y_hw)*0.2)) # 1 año o ~20% si no alcanza n &lt;- length(y_hw) y_train &lt;- window(y_hw, end = time(y_hw)[n - h_test]) y_test &lt;- window(y_hw, start = time(y_hw)[n - h_test + 1]) autoplot(y_hw) + geom_vline(xintercept = time(y_hw)[n - h_test + 1], linetype = 2) + labs(title = &quot;Serie completa con corte train/test&quot;, y = &quot;Precio promedio&quot;, x = &quot;Tiempo&quot;) + theme_minimal() Se prepara la validación del modelo. La serie se divide en y_train y y_test. Es crucial en series de tiempo usar window() y no un muestreo aleatorio, ya que el orden temporal debe preservarse. 3.3.2 Agregación semanal library(zoo) # y_hw: serie ts diaria (freq=365) stopifnot(frequency(y_hw) %in% c(365, 366)) #secuencia de fechas real para la ts diaria tsp_hw &lt;- tsp(y_hw) # c(start, end, freq) start_year &lt;- floor(tsp_hw[1]) start_frac &lt;- tsp_hw[1] - start_year start_date &lt;- as.Date(paste0(start_year, &quot;-01-01&quot;)) + round(start_frac * 365.25) fechas_all &lt;- seq.Date(from = start_date, by = &quot;day&quot;, length.out = length(y_hw)) z_all &lt;- zoo(as.numeric(y_hw), fechas_all) #Agregar por semana calendario z_week &lt;- aggregate(z_all, as.Date(cut(index(z_all), &quot;week&quot;)), mean, na.rm = TRUE) #Convertimos a ts semanal (freq = 52) y_w &lt;- ts(as.numeric(z_week), frequency = 52) #Split train/test semanal h_test_w &lt;- min(52, floor(length(y_w) * 0.2)) n_w &lt;- length(y_w) y_train_w &lt;- window(y_w, end = time(y_w)[n_w - h_test_w]) y_test_w &lt;- window(y_w, start = time(y_w)[n_w - h_test_w + 1]) autoplot(y_w) + geom_vline(xintercept = time(y_w)[n_w - h_test_w + 1], linetype = 2) + labs(title = &quot;Serie semanal con corte train/test&quot;, y = &quot;Precio promedio semanal&quot;, x = &quot;Tiempo&quot;) + theme_minimal() Modelar una estacionalidad de 365 períodos es computacionalmente inviable y estadísticamente inestable para HoltWinters o ets. Mediante la agregación de los datos a una frecuencia menor que aún capture la estacionalidad (en este caso se escogió semanal el problema de soluciona, generando una nueva ts semanal y se aplica nuevamente la división de los datos en train y test 3.3.3 Modelos de suavizamiento y Holt-Winters en serie semanal # Horizonte de prueba h &lt;- length(y_test_w) # Modelos de suavizamiento base # Suavizamiento exponencial simple (SES) fit_ses_w &lt;- ets(y_train_w, model = &quot;ANN&quot;) fc_ses_w &lt;- forecast(fit_ses_w, h = h) # Holt: tendencia aditiva fit_holt_w &lt;- ets(y_train_w, model = &quot;AAN&quot;) fc_holt_w &lt;- forecast(fit_holt_w, h = h) # Holt-Winters con función base stats::HoltWinters fit_hwa_w &lt;- HoltWinters(y_train_w, seasonal = &quot;additive&quot;) fit_hwm_w &lt;- HoltWinters(y_train_w, seasonal = &quot;multiplicative&quot;) # Generar pronósticos a h pasos fc_hwa_w &lt;- forecast(fit_hwa_w, h = h) fc_hwm_w &lt;- forecast(fit_hwm_w, h = h) # Resumen de parámetros de suavizamiento pars_w &lt;- list( SES = fit_ses_w$par, Holt = fit_holt_w$par, HW_adi = fit_hwa_w$coefficients, HW_multi = fit_hwm_w$coefficients ) metodos_w &lt;- c( SES = fit_ses_w$method, Holt = fit_holt_w$method, HW_adi = &quot;Holt-Winters aditivo (HoltWinters)&quot;, HW_mul = &quot;Holt-Winters multiplicativo (HoltWinters)&quot; ) list(pars = pars_w, metodos = metodos_w) ## $pars ## $pars$SES ## alpha l ## 0.9998999 20.0661412 ## ## $pars$Holt ## alpha beta phi l b ## 0.9998998 0.1131366 0.8000015 19.3507661 0.7318030 ## ## $pars$HW_adi ## a b s1 s2 s3 s4 ## 39.08244375 0.07882721 -7.65617219 -5.33129937 -2.12172776 -0.60521373 ## s5 s6 s7 s8 s9 s10 ## 1.67227131 3.70855086 3.86297747 4.29730738 4.70950257 5.51286110 ## s11 s12 s13 s14 s15 s16 ## 6.58108183 9.34052131 11.67282675 11.56985459 10.72690049 10.62915737 ## s17 s18 s19 s20 s21 s22 ## 11.56624926 14.32396189 12.96493891 12.91210622 15.60833595 19.70484488 ## s23 s24 s25 s26 s27 s28 ## 18.21542017 15.04288451 8.57289145 4.41893044 3.59468994 2.26948285 ## s29 s30 s31 s32 s33 s34 ## 1.41348224 1.16589200 0.07345107 -2.59161738 -5.38569070 -6.81747767 ## s35 s36 s37 s38 s39 s40 ## -8.35116126 -10.31002086 -14.36805886 -15.48013931 -13.59119371 -14.10375330 ## s41 s42 s43 s44 s45 s46 ## -12.98609882 -13.91879059 -12.80762063 -12.45344901 -10.91079687 -9.50278976 ## s47 s48 s49 s50 s51 s52 ## -7.48181474 -7.63951511 -9.66359895 -9.41494901 -8.19836375 -8.36815804 ## ## $pars$HW_multi ## a b s1 s2 s3 s4 ## 40.06957603 0.07882721 0.78984647 0.86149189 0.95592829 0.99520880 ## s5 s6 s7 s8 s9 s10 ## 1.06150922 1.11859277 1.10742123 1.11547832 1.13362719 1.15295252 ## s11 s12 s13 s14 s15 s16 ## 1.19755872 1.28051297 1.34512974 1.33136792 1.29845693 1.29564795 ## s17 s18 s19 s20 s21 s22 ## 1.31337013 1.37966490 1.36129664 1.37542631 1.45910223 1.55273805 ## s23 s24 s25 s26 s27 s28 ## 1.49801968 1.41880910 1.25803359 1.12986066 1.10809063 1.06878253 ## s29 s30 s31 s32 s33 s34 ## 1.05012792 1.03448499 1.00251606 0.92562241 0.84794487 0.78549769 ## s35 s36 s37 s38 s39 s40 ## 0.73966473 0.68969443 0.59218461 0.55743071 0.58537805 0.58407654 ## s41 s42 s43 s44 s45 s46 ## 0.61227139 0.60444293 0.63415394 0.64018299 0.67488001 0.72564177 ## s47 s48 s49 s50 s51 s52 ## 0.78927007 0.78769837 0.73692250 0.74269354 0.77194581 0.76652385 ## ## ## $metodos ## SES ## &quot;ETS(A,N,N)&quot; ## Holt ## &quot;ETS(A,Ad,N)&quot; ## HW_adi ## &quot;Holt-Winters aditivo (HoltWinters)&quot; ## HW_mul ## &quot;Holt-Winters multiplicativo (HoltWinters)&quot; Se ajustan cuatro modelos de suavizamiento exponencial al conjunto de entrenamiento semanal (y_train_w). Se evaluán los modelos ANN más conocido como SES (Error Aditivo, sin tendencia, sin estacionalidad). Por otra parte el modelo Holt es un modelo con Error Aditivo, Tendencia Aditiva y sin Estacionalidad. Y por último, el modelo HoltWinters es un modelo completo que asume que la estacionalidad es constante. 3.3.4 Comparación de precisión fuera de muestra Se calcula la precisión de los pronósticos de cada modelo contra los datos reales y_test_w. Se comparan las métricas de error (RMSE, MAE, MAPE) del conjunto de prueba. # Calcular métricas de error para cada modelo en el conjunto de prueba acc_tbl &lt;- bind_rows( data.frame(model = &quot;SES&quot;, accuracy(fc_ses_w, y_test_w)), data.frame(model = &quot;Holt&quot;, accuracy(fc_holt_w, y_test_w)), data.frame(model = &quot;HW_adi&quot;, accuracy(fc_hwa_w, y_test_w)), data.frame(model = &quot;HW_mul&quot;, accuracy(fc_hwm_w, y_test_w)) ) %&gt;% select(model, RMSE, MAE, MAPE) acc_tbl ## model RMSE MAE MAPE ## Training set...1 SES 2.929804 1.928708 5.748854 ## Test set...2 SES 33.778723 24.276695 34.505452 ## Training set...3 Holt 2.902352 1.901817 5.638535 ## Test set...4 Holt 34.593228 24.973105 35.456690 ## Training set...5 HW_adi 2.984060 2.102575 6.453931 ## Test set...6 HW_adi 20.668712 14.555681 20.798164 ## Training set...7 HW_mul 2.846973 1.996849 6.036061 ## Test set...8 HW_mul 18.997168 13.487363 19.577035 El modelo Holt-Winters multiplicativo (HW_mul) es el mejor, porque presenta los errores más bajos (RMSE y MAPE) en la ventana de prueba. Esto indica que la estacionalidad es proporcional al nivel de la serie (los picos crecen cuando el nivel general sube), lo cual es consistente con lo que se veia en el grafico. 3.3.5 Diagnostico de residuos Se realizarán dos pruebas estadísticas al pronóstico ganador. Por una parte el Gráfico ACF de Residuos, muestra la autocorrelación de los errores del modelo. Idealmente, ningún rezago debe superar las líneas azules. Esto significaría que los errores son “ruido blanco” y que el modelo ha capturado toda la información predecible.En segundo lugar, la Prueba Ljung-Box es la prueba estadística formal para la autocorrelación de los residuos.Hipótesis Nula (H_0): Los residuos son independientes (son ruido blanco). best_fc &lt;- fc_hwm_w # ganador: Holt-Winters multiplicativo checkresiduals(best_fc$model) ## ## Ljung-Box test ## ## data: Residuals from HoltWinters ## Q* = 76.422, df = 62, p-value = 0.1029 ## ## Model df: 0. Total lags used: 62 Al comparar los modelos de suavizamiento, Holt y Holt-Winters, se encontró que el Holt-Winters multiplicativo obtuvo los mejores resultados en la ventana de prueba, con los menores valores de RMSE (18.99) y MAPE (19.57 %). Esto indica que la serie presenta una estacionalidad proporcional al nivel, es decir, las fluctuaciones son más amplias cuando los valores son altos. El análisis de residuos respalda la adecuación del modelo: el p-valor = 0.1029 del test de Ljung-Box confirma que no existe autocorrelación significativa (residuos ≈ ruido blanco). Por tanto, el modelo Holt-Winters multiplicativo logra capturar adecuadamente la tendencia y la estacionalidad de la serie semanal del precio promedio del Potato Red. 3.3.6 Pronostico final Reentrenamiento: Ahora que hemos probado que el modelo HW Multiplicativo es el mejor, lo reentrenamos usando todos los datos semanales (y_w), no solo el conjunto de entrenamiento. Esto le da al modelo la mayor cantidad de información posible para estimar los parámetros finales. Pronóstico: Se genera el pronóstico final hacia el futuro (h = 52 semanas, un año). # Reentrenar el modelo Holt-Winters multiplicativo con toda la serie semanal fit_final_hw &lt;- HoltWinters(y_w, seasonal = &quot;multiplicative&quot;) # pronóstico a 52 semanas (≈ 1 año) h_future &lt;- 52 fc_final_hw &lt;- forecast(fit_final_hw, h = h_future) # Visualizacion del pronóstico final autoplot(fc_final_hw) + labs( title = &quot;Pronostico final Holt-Winters multiplicativo (52 semanas)&quot;, y = &quot;Precio promedio semanal&quot;, x = &quot;Tiempo&quot; ) + theme_minimal() # primeras filas de la tabla de pronostico head(data.frame( Semana = time(fc_final_hw$mean), Pronostico = round(as.numeric(fc_final_hw$mean), 2), LI_80 = round(fc_final_hw$lower[,1], 2), LS_80 = round(fc_final_hw$upper[,1], 2), LI_95 = round(fc_final_hw$lower[,2], 2), LS_95 = round(fc_final_hw$upper[,2], 2) ), 10) ## Semana Pronostico LI_80 LS_80 LI_95 LS_95 ## 1 8.961538 37.69 33.31 42.07 30.99 44.39 ## 2 8.980769 40.88 35.05 46.72 31.96 49.81 ## 3 9.000000 45.08 37.83 52.33 33.99 56.16 ## 4 9.019231 47.46 39.09 55.83 34.66 60.26 ## 5 9.038462 50.77 41.19 60.34 36.13 65.41 ## 6 9.057692 55.25 44.31 66.19 38.52 71.98 ## 7 9.076923 55.96 44.35 67.58 38.20 73.73 ## 8 9.096154 55.31 43.30 67.32 36.95 73.67 ## 9 9.115385 55.66 43.09 68.24 36.43 74.90 ## 10 9.134615 58.37 44.76 71.99 37.55 79.20 3.3.7 Conclusiones Tras evaluar diferentes métodos de suavizamiento exponencial, se determinó que el modelo Holt-Winters multiplicativo fue el que presentó el mejor desempeño predictivo, con los menores errores (RMSE = 18.99 y MAPE = 19.6 %) en la ventana de prueba. Este resultado confirma que la serie presenta estacionalidad proporcional al nivel, es decir, cuando el precio promedio del Potato Red aumenta, las fluctuaciones también lo hacen en la misma proporción. Los residuos del modelo no mostraron autocorrelación significativa (p-valor = 0.1029), por lo que se concluye que el modelo explica adecuadamente la estructura temporal. Con la serie completa y el modelo reentrenado, el pronóstico a 52 semanas muestra una tendencia oscilante con picos regulares y amplitud similar a la observada históricamente. Las bandas de confianza (80 % y 95 %) reflejan un nivel de incertidumbre moderado, lo que otorga confianza en las estimaciones. En conjunto, el método Holt-Winters multiplicativo demuestra ser una herramienta sólida y confiable para proyectar el comportamiento estacional del precio semanal del Potato Red. 3.4 Desarrollo metodológico y justificación de decisiones El proceso de aplicación del modelo de Holt-Winters a la serie de tiempo del precio promedio del Potato Red implicó diversos ajustes metodológicos debido a las características particulares de los datos. La variable de estudio correspondía a una serie diaria con una extensión superior a 2800 observaciones y frecuencia anual de 365. Si bien esta cantidad de datos representaba una fuente valiosa de información, también generó limitaciones computacionales al momento de ajustar modelos estacionales como ets(model = “AAA”) o hw(seasonal = “additive”), debido a que la función ets()` no está optimizada para manejar estacionalidades tan largas. Durante los primeros intentos, el software arrojó el error “Frequency too high” o se quedaba ejecutando indefinidamente. Esto motivó una revisión del enfoque, identificando que la estacionalidad de interés no necesariamente se presentaba de manera diaria, sino más bien en ciclos semanales o mensuales, propios de los precios agrícolas. 3.4.1 Ajuste de la frecuencia temporal Como solución, se decidió agregar la serie a frecuencia semanal, calculando el promedio de los precios diarios. Esta decisión permitió conservar la forma cíclica de la serie (picos y valles regulares) y, al mismo tiempo, reducir la frecuencia de 365 a 52, lo cual hizo posible aplicar modelos estacionales de forma estable y con un tiempo de cómputo razonable. En la práctica, esto significó reconstruir la serie con una frecuencia semanal (frequency = 52), evitando la sobrecarga que impedía el ajuste de Holt-Winters en la versión original. 3.4.2 Modelos aplicados Una vez ajustada la frecuencia, se implementaron cuatro modelos de suavizamiento: Suavizamiento exponencial simple (SES) – Captura únicamente el nivel de la serie. Método de Holt – Incorpora tendencia aditiva. Holt-Winters aditivo – Considera tendencia y estacionalidad de amplitud constante. Holt-Winters multiplicativo – Considera estacionalidad proporcional al nivel. Debido a los errores recurrentes con ets() y hw(), se optó finalmente por la función stats::HoltWinters(), que permite ajustar modelos estacionales de manera más estable con series largas o de alta frecuencia. 3.4.3 Validación del modelo La serie semanal se dividió en un conjunto de entrenamiento (80%) y otro de prueba (20%), correspondiente aproximadamente a un año de observaciones. Con esta división, se evaluó el desempeño predictivo de cada modelo mediante métricas como RMSE, MAE y MAPE. Los resultados mostraron que el modelo Holt-Winters multiplicativo presentó el mejor desempeño (RMSE = 18.99, MAPE = 19.6%), superando a las versiones aditiva, Holt y SES. Esto indica que la estacionalidad es proporcional al nivel de la serie: cuando los precios son altos, las fluctuaciones semanales también lo son. 3.4.4 Diagnóstico de residuos Para validar el ajuste, se analizaron los residuos del modelo Holt-Winters multiplicativo. El test de Ljung-Box (p-valor = 0.1029) indicó ausencia de autocorrelación significativa, lo cual demuestra que el modelo logra capturar adecuadamente la tendencia y la estacionalidad de los datos. Además, el gráfico ACF de los residuos no mostró patrones sistemáticos, confirmando que el error se comporta como ruido blanco. 3.4.5 Pronóstico final Con base en el modelo seleccionado, se reentrenó la serie completa y se realizó un pronóstico a 52 semanas (equivalente a un año). El resultado mostró una evolución oscilante, con picos estacionales regulares y una amplitud coherente con los patrones históricos observados. Las bandas de confianza del 80% y 95% se mantuvieron en rangos moderados, reflejando un nivel de incertidumbre aceptable. 3.4.6 Conclusión integradora En síntesis, el desarrollo de este modelo implicó un proceso iterativo de ajuste y validación. Se comprobó que aplicar Holt-Winters directamente sobre la serie diaria era impracticable por su frecuencia alta, por lo que fue necesario agregar la serie a frecuencia semanal para estabilizar el modelo. Este cambio permitió aplicar el método de forma exitosa y obtener resultados coherentes, concluyendo que el modelo Holt-Winters multiplicativo es una herramienta sólida para pronosticar el comportamiento estacional del precio del Potato Red, combinando buena precisión y consistencia temporal. "],["modelos-estacionales-en-series-de-tiempo.html", "Capítulo 4 Modelos Estacionales en Series de Tiempo 4.1 Exploración inicial de datos 4.2 Analisis de series de tiempo 4.3 Serie basica y ACF 4.4 Suavizamiento temporal 4.5 Promedios moviles (evidencia de suavizado) 4.6 Promedios móviles (7 y 30) — Base R + PNG + include 4.7 Serie básica (ts) — Base R + PNG + include 4.8 2.4 STL — Base R + PNG + include 4.9 Estacionalidad (descomposicion STL) 4.10 Estacionariedad y diferenciación 4.11 Verificación de estacionariedad (ADF Test) 4.12 Interpretacion 4.13 AJUSTE DEL MODELO ARIMA 4.14 Criterios de selección 4.15 Suavizamiento y Holt-Winters sobre la variable tiempo 4.16 Particion de entrenamiento /prueba 4.17 Modelos de suavizamiento y Holt-Winters en serie semanal 4.18 Comparación de presición fuera de muestra 4.19 Diagnostico de residuos 4.20 Pronostico final 4.21 Conclusiones 4.22 Desarrollo metodológico y justificación de decisiones 4.23 Ajuste de la frecuencia temporal 4.24 Modelos aplicados 4.25 Validación del modelo 4.26 Diagnóstico de residuos 4.27 Pronóstico final 4.28 Conclusión integradora 4.29 Ajuste e interpretación del modelo ARIMA/SARIMA - Box-Jenkins (ARIMA) 4.30 Pronostico a h pasos y metricas RMSE/MAE/MAPE 4.31 Diagnostico de residuos 4.32 Pronostico final Sarima (1,0,0)(0,1,0)[52] 4.33 Interpretación del modelo 4.34 Reflexión y justificación del proceso Box–Jenkins 4.35 Ajustes metodológicos y rendimiento computacional 4.36 Evaluación del modelo 4.37 Reflexión metodológica final 4.38 EVALUACIÓN DEL MODELO 4.39 PRONOSTICO Y CONCLUSIONES 4.40 CONCLUSIONES GENERALES FINALES", " Capítulo 4 Modelos Estacionales en Series de Tiempo Realizaremos nuestro analisis con un conjunto de datos de precios agrícolas proveniente del mercado de Kalimati (Nepal). Este dataset incluye información diaria sobre productos agrícolas, sus precios mínimos, máximos y promedio. A partir de estos datos se realizará un análisis exploratorio y un estudio de comportamiento temporal de los precios. csv_file &lt;- &quot;C:/Users/Steba/OneDrive/Escritorio/kalimati_tarkari_dataset (2).csv&quot; 4.1 Exploración inicial de datos El conjunto de datos analizado corresponde a registros diarios de precios de productos agrícolas del mercado de Kalimati (Nepal). Para el caso del producto agrícola analizado “Potato Red”, se estandarizaron nombres de variables y se mapearon columnas clave (Commodity, Date, Minimum, Maximum, Average). Se realizaron verificaciones de tipo y consistencia (fechas válidas, numéricos no negativos, duplicados) y un análisis descriptivo de la variable de interés (Average), complementado con gráficos de distribución. Hallazgos principales. La distribución de precios promedio presentó una leve asimetría positiva, consistente con valores ocasionalmente altos. Las medidas de tendencia central (media y mediana) y de dispersión (desviación estándar y rango) indicaron una variabilidad moderada, coherente con mercados agrícolas con choques transitorios en oferta (cosecha, clima, logística). 4.1.1 Lectura de datos # Leer datos data_raw &lt;- readr::read_csv(csv_file, show_col_types = FALSE) # Estandarizar nombres a snake para facilitar mapeo nms &lt;- tolower(gsub(&quot;[^a-zA-Z0-9]+&quot;, &quot;_&quot;, names(data_raw))) # Intentar mapear columnas canonicas (Commodity / Date / Minimum / Maximum / Average) df &lt;- data_raw names(df) &lt;- nms # Mapeo flexible (case-insensitive) pick_first &lt;- function(cands) { hit &lt;- intersect(cands, names(df)) if (length(hit) == 0) return(NA_character_) else return(hit[1]) } col_commodity &lt;- pick_first(c(&quot;commodity&quot;,&quot;item&quot;,&quot;product&quot;,&quot;variety&quot;,&quot;name&quot;)) col_date &lt;- pick_first(c(&quot;date&quot;,&quot;fecha&quot;,&quot;day&quot;)) col_min &lt;- pick_first(c(&quot;minimum&quot;,&quot;min&quot;,&quot;min_price&quot;,&quot;price_min&quot;)) col_max &lt;- pick_first(c(&quot;maximum&quot;,&quot;max&quot;,&quot;max_price&quot;,&quot;price_max&quot;)) col_avg &lt;- pick_first(c(&quot;average&quot;,&quot;avg&quot;,&quot;avg_price&quot;,&quot;price_avg&quot;,&quot;mean_price&quot;)) req &lt;- c(col_commodity, col_date, col_min, col_max, col_avg) if (any(is.na(req))) { stop(&quot;No fue posible mapear columnas clave (commodity/date/min/max/average). Revisa nombres del CSV: &quot;, paste(names(df), collapse = &quot;, &quot;)) } # --- Cargar librerías necesarias --- libs &lt;- c(&quot;dplyr&quot;, &quot;tidyr&quot;, &quot;lubridate&quot;, &quot;stringr&quot;, &quot;tseries&quot;) for (pkg in libs) { if (!require(pkg, character.only = TRUE)) { install.packages(pkg, dependencies = TRUE) library(pkg, character.only = TRUE) } } ## Loading required package: dplyr ## Warning: package &#39;dplyr&#39; was built under R version 4.3.3 ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union ## Loading required package: tidyr ## Warning: package &#39;tidyr&#39; was built under R version 4.3.3 ## Loading required package: lubridate ## Warning: package &#39;lubridate&#39; was built under R version 4.3.3 ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union ## Loading required package: stringr ## Warning: package &#39;stringr&#39; was built under R version 4.3.3 ## Loading required package: tseries ## Warning: package &#39;tseries&#39; was built under R version 4.3.3 ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo # Asegurar el operador %&gt;% disponible if (!exists(&quot;%&gt;%&quot;)) { library(magrittr) } 4.1.2 Transformación inicial de datos data &lt;- df %&gt;% transmute( Commodity = .data[[col_commodity]], Date = as.Date(.data[[col_date]]), Unit = NA_character_, Minimum = as.numeric(.data[[col_min]]), Maximum = as.numeric(.data[[col_max]]), Average = as.numeric(.data[[col_avg]]) ) # Chequeos basicos stopifnot(inherits(data$Date, &quot;Date&quot;)) ###Vista previa de los datos # Vista previa y estructura head(data) ## # A tibble: 6 × 6 ## Commodity Date Unit Minimum Maximum Average ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Tomato Big(Nepali) 2013-06-16 &lt;NA&gt; 35 40 37.5 ## 2 Tomato Small(Local) 2013-06-16 &lt;NA&gt; 26 32 29 ## 3 Potato Red 2013-06-16 &lt;NA&gt; 20 21 20.5 ## 4 Potato White 2013-06-16 &lt;NA&gt; 15 16 15.5 ## 5 Onion Dry (Indian) 2013-06-16 &lt;NA&gt; 28 30 29 ## 6 Carrot(Local) 2013-06-16 &lt;NA&gt; 30 35 32.5 str(data) ## tibble [197,161 × 6] (S3: tbl_df/tbl/data.frame) ## $ Commodity: chr [1:197161] &quot;Tomato Big(Nepali)&quot; &quot;Tomato Small(Local)&quot; &quot;Potato Red&quot; &quot;Potato White&quot; ... ## $ Date : Date[1:197161], format: &quot;2013-06-16&quot; &quot;2013-06-16&quot; ... ## $ Unit : chr [1:197161] NA NA NA NA ... ## $ Minimum : num [1:197161] 35 26 20 15 28 30 6 30 35 25 ... ## $ Maximum : num [1:197161] 40 32 21 16 30 35 10 35 40 30 ... ## $ Average : num [1:197161] 37.5 29 20.5 15.5 29 32.5 8 32.5 37.5 27.5 ... summary(data) ## Commodity Date Unit Minimum ## Length:197161 Min. :2013-06-16 Length:197161 Min. : 1.00 ## Class :character 1st Qu.:2015-08-24 Class :character 1st Qu.: 40.00 ## Mode :character Median :2017-08-03 Mode :character Median : 60.00 ## Mean :2017-08-09 Mean : 85.42 ## 3rd Qu.:2019-08-27 3rd Qu.: 100.00 ## Max. :2021-05-13 Max. :1800.00 ## Maximum Average ## Min. : 6.00 Min. : 5.00 ## 1st Qu.: 45.00 1st Qu.: 42.50 ## Median : 70.00 Median : 65.00 ## Mean : 94.16 Mean : 89.79 ## 3rd Qu.: 110.00 3rd Qu.: 105.00 ## Max. :2000.00 Max. :1900.00 4.1.3 Datos nulos y duplicados # NAs y duplicados generales sum(is.na(data)) ## [1] 197161 sum(duplicated(data)) ## [1] 0 if (!require(ggplot2)) { install.packages(&quot;ggplot2&quot;) library(ggplot2) } ## Loading required package: ggplot2 4.1.4 Análisis Univariado #analisis univariado ggplot(data, aes(x = Average)) + geom_histogram(binwidth = 5, fill = &quot;blue&quot;, color = &quot;black&quot;, alpha = 0.7) + labs(title = &quot;Distribucion de Precios Promedio&quot;, x = &quot;Precio Promedio&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() data %&gt;% summarise( Mean = mean(Average, na.rm = TRUE), Median = median(Average, na.rm = TRUE), SD = sd(Average, na.rm = TRUE), Min = min(Average, na.rm = TRUE), Max = max(Average, na.rm = TRUE) ) ## # A tibble: 1 × 5 ## Mean Median SD Min Max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 89.8 65 79.6 5 1900 4.1.5 Análisis Bivariado #analisis bivariado ggplot(data, aes(x = Minimum, y = Maximum)) + geom_point(alpha = 0.5) + labs(title = &quot;Relacion entre Precio Minimo y Maximo&quot;, x = &quot;Precio Minimo&quot;, y = &quot;Precio Maximo&quot;) + theme_minimal() cor(data$Minimum, data$Maximum, use = &quot;complete.obs&quot;) ## [1] 0.9950614 4.2 Analisis de series de tiempo if (&quot;Potato Red&quot; %in% unique(data$Commodity)) { target_item &lt;- &quot;Potato Red&quot; } else { target_item &lt;- data %&gt;% count(Commodity, sort = TRUE) %&gt;% slice(1) %&gt;% pull(Commodity) } target_item ## [1] &quot;Potato Red&quot; # Filtrar y regularizar serie diaria potatored &lt;- data %&gt;% filter(Commodity == target_item) %&gt;% select(Date, Average) %&gt;% group_by(Date) %&gt;% summarise(Average = mean(Average), .groups = &quot;drop&quot;) %&gt;% complete(Date = seq(min(Date, na.rm = TRUE), max(Date, na.rm = TRUE), by = &quot;day&quot;)) %&gt;% arrange(Date) # Construir objeto ts (diario, 365) pot_ts &lt;- ts( potatored$Average, start = c(lubridate::year(min(potatored$Date, na.rm = TRUE)), lubridate::yday(min(potatored$Date, na.rm = TRUE))), frequency = 365 ) 4.3 Serie basica y ACF # --- Hotfix para error &quot;rstudio$.rs.isDesktop()&quot; --- if (exists(&quot;rstudio&quot;, envir = .GlobalEnv)) rm(&quot;rstudio&quot;, envir = .GlobalEnv) options(device.ask.default = FALSE) if (capabilities(&quot;cairo&quot;)) { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150, dev.args = list(type = &quot;cairo&quot;)) options(bitmapType = &quot;cairo&quot;) } else { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150) } try(graphics.off(), silent = TRUE) library(ggplot2) library(forecast) ## Warning: package &#39;forecast&#39; was built under R version 4.3.3 autoplot(pot_ts) + labs( title = &quot; Serie de tiempo: precio promedio&quot;, y = &quot;Precio promedio&quot;, x = &quot;Tiempo&quot; ) + theme_minimal(base_size = 12) + theme( plot.title = element_text(face = &quot;bold&quot;, color = &quot;#2C3E50&quot;, size = 15), axis.title = element_text(face = &quot;bold&quot;, color = &quot;#34495E&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;grey90&quot;) ) ggAcf(pot_ts) + labs(title = &quot;ACF del precio promedio (diario)&quot;) 4.4 Suavizamiento temporal Con el objetivo de aclarar la señal subyacente y separar ruido de corto plazo, se aplicaron promedios móviles (MA) de 7 y 30 días sobre la serie diaria de Average. El MA(7) capturó ciclos intra-semanales asociados a dinámica de mercado y logística, mientras que el MA(30) reveló una tendencia más estructural. Interpretación. El patrón suavizado sugiere una tendencia suave al alza con episodios de fluctuación estacional. Este hallazgo justifica el uso posterior de modelos con componentes de tendencia y estacionalidad, y confirma la presencia de persistencia temporal (autocorrelación positiva en rezagos cortos), lo que anticipa buen desempeño de métodos como ARIMA/ETS. 4.5 Promedios moviles (evidencia de suavizado) if (exists(&quot;rstudio&quot;, envir = .GlobalEnv)) rm(&quot;rstudio&quot;, envir = .GlobalEnv) options(device.ask.default = FALSE) if (capabilities(&quot;cairo&quot;)) { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150, dev.args = list(type = &quot;cairo&quot;)) options(bitmapType = &quot;cairo&quot;) } else { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150) } # Hotfix global para gráficos (evita el viewer de RStudio) if (exists(&quot;rstudio&quot;, envir = .GlobalEnv)) rm(&quot;rstudio&quot;, envir = .GlobalEnv) options(device.ask.default = FALSE) if (capabilities(&quot;cairo&quot;)) { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150, dev.args = list(type = &quot;cairo&quot;)) options(bitmapType = &quot;cairo&quot;) } else { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150) } # Hotfix global para gráficos (evita el viewer de RStudio) if (exists(&quot;rstudio&quot;, envir = .GlobalEnv)) rm(&quot;rstudio&quot;, envir = .GlobalEnv) options(device.ask.default = FALSE) if (capabilities(&quot;cairo&quot;)) { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150, dev.args = list(type = &quot;cairo&quot;)) options(bitmapType = &quot;cairo&quot;) } else { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150) } # --- Hotfix global: NO viewer, render a PNG --- if (exists(&quot;rstudio&quot;, envir = .GlobalEnv)) rm(&quot;rstudio&quot;, envir = .GlobalEnv) options(device.ask.default = FALSE) if (capabilities(&quot;cairo&quot;)) { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150, dev.args = list(type = &quot;cairo&quot;)) options(bitmapType = &quot;cairo&quot;) } else { knitr::opts_chunk$set(dev = &quot;png&quot;, dpi = 150) } # Paquetes mínimos libs &lt;- c(&quot;dplyr&quot;,&quot;tidyr&quot;,&quot;lubridate&quot;,&quot;slider&quot;) for (p in libs) if (!require(p, character.only=TRUE)) {install.packages(p); library(p, character.only=TRUE)} ## Loading required package: slider ## Warning: package &#39;slider&#39; was built under R version 4.3.3 # Utilidad para guardar junto al Rmd safe_dir &lt;- function(){ f &lt;- tryCatch(knitr::current_input(), error=function(e) NULL) if (!is.null(f) &amp;&amp; nzchar(f)) dirname(normalizePath(f)) else getwd() } 4.6 Promedios móviles (7 y 30) — Base R + PNG + include # ... fig_path &lt;- &quot;figuras/stl2.png&quot; # ... message(&quot;⚠️ La imagen &#39;stl2.png&#39; aún no existe...&quot;) ## ⚠️ La imagen &#39;stl2.png&#39; aún no existe... 4.7 Serie básica (ts) — Base R + PNG + include # Crear carpeta de figuras si no existe if (!dir.exists(&quot;figuras&quot;)) dir.create(&quot;figuras&quot;, recursive = TRUE) # Definir ruta de salida del gráfico outfile &lt;- file.path(&quot;figuras&quot;, &quot;serie_basica.png&quot;) # Generar y guardar el gráfico if (capabilities(&quot;cairo&quot;)) { png(outfile, width = 1400, height = 600, res = 150, type = &quot;cairo&quot;) } else { png(outfile, width = 1400, height = 600, res = 150) } op &lt;- par(mar = c(4, 4, 3, 1), mgp = c(2.2, 0.8, 0)) plot( potatored$Date, potatored$Average, type = &quot;l&quot;, col = &quot;#1F77B4&quot;, lwd = 1.2, xlab = &quot;Fecha&quot;, ylab = &quot;Precio promedio&quot;, main = &quot;Serie de tiempo: precio promedio&quot; ) par(op) dev.off() ## png ## 2 # Mostrar la imagen generada (método estandarizado) knitr::include_graphics(outfile) 4.8 2.4 STL — Base R + PNG + include # Asegurar que la carpeta &#39;figuras&#39; exista (relativa al proyecto) if (!dir.exists(&quot;figuras&quot;)) dir.create(&quot;figuras&quot;, recursive = TRUE) # Definir la ruta de salida estándar outfile &lt;- file.path(&quot;figuras&quot;, &quot;stl.png&quot;) # --- Lógica de cálculo STL (existente) --- y &lt;- ts(potatored$Average, frequency = 365) # interp lineal base (necesaria para STL si hay NAs) y &lt;- approx(seq_along(y), y, xout=seq_along(y))$y fit &lt;- stl(ts(y, frequency=365), s.window=&quot;periodic&quot;, robust=TRUE) # --- Fin lógica de cálculo --- # Generar y guardar el gráfico if (capabilities(&quot;cairo&quot;)) { png(outfile, width=1400, height=900, res=150, type=&quot;cairo&quot;) } else { png(outfile, width=1400, height=900, res=150) } op &lt;- par(mfrow=c(4,1), mar=c(3,4,2,1)) plot(fit$time.series[,&quot;remainder&quot;], type=&quot;l&quot;, col=&quot;#7D3C98&quot;, main=&quot;Residuo&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;) plot(fit$time.series[,&quot;seasonal&quot;], type=&quot;l&quot;, col=&quot;#117A65&quot;, main=&quot;Estacionalidad&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;) plot(fit$time.series[,&quot;trend&quot;], type=&quot;l&quot;, col=&quot;#E67E22&quot;, main=&quot;Tendencia&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;) plot(y, type=&quot;l&quot;, col=&quot;#1F77B4&quot;, main=&quot;Serie (interpolada)&quot;, xlab=&quot;Tiempo&quot;, ylab=&quot;&quot;) par(op); dev.off() ## png ## 2 # Incluir la imagen guardada en el bookdown # Esta línea reemplaza el &#39;cat(sprintf(...))&#39; knitr::include_graphics(outfile) # --- Promedios móviles (gráfico generado automáticamente) --- if (!dir.exists(&quot;figuras&quot;)) dir.create(&quot;figuras&quot;, recursive = TRUE) fig_path &lt;- &quot;figuras/promedios_moviles.png&quot; # Generar el gráfico y guardarlo png(fig_path, width = 1200, height = 600, res = 150) plot(potatored$Average, type = &quot;l&quot;, col = &quot;steelblue&quot;, main = &quot;Promedios móviles (7 y 30 días)&quot;, ylab = &quot;Precio promedio&quot;, xlab = &quot;Tiempo&quot;) lines(stats::filter(potatored$Average, rep(1/7,7)), col = &quot;red&quot;, lwd = 2) lines(stats::filter(potatored$Average, rep(1/30,30)), col = &quot;green&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;7 días&quot;, &quot;30 días&quot;), col = c(&quot;steelblue&quot;, &quot;red&quot;, &quot;green&quot;), lty = 1, lwd = 2) dev.off() ## png ## 2 # Mostrar la imagen knitr::include_graphics(fig_path) ## Rezagos (lags) y dependencia temporal pot_lags &lt;- potatored %&gt;% mutate( lag1 = dplyr::lag(Average, 1), lag7 = dplyr::lag(Average, 7), lag30 = dplyr::lag(Average, 30) ) # Scatter y_t vs y_{t-1} ggplot(pot_lags, aes(lag1, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 1 (y_t vs y_{t-1})&quot;, x = &quot;y_{t-1}&quot;, y = &quot;y_t&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 251 rows containing non-finite outside the scale range ## (`stat_smooth()`). ## Warning: Removed 251 rows containing missing values or values outside the scale range ## (`geom_point()`). # Scatter y_t vs y_{t-7} ggplot(pot_lags, aes(lag7, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 7 (aprox. semanal)&quot;, x = &quot;y_{t-7}&quot;, y = &quot;y_t&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 234 rows containing non-finite outside the scale range ## (`stat_smooth()`). ## Warning: Removed 234 rows containing missing values or values outside the scale range ## (`geom_point()`). # ACF/PACF (serie regularizada) ggAcf(pot_ts) + labs(title = &quot;ACF precio promedio (diario)&quot;) ggPacf(pot_ts) + labs(title = &quot;PACF precio promedio (diario)&quot;) 4.9 Estacionalidad (descomposicion STL) fit_stl &lt;- stl(na.interp(pot_ts), s.window = &quot;periodic&quot;, robust = TRUE) autoplot(fit_stl) + labs(title = &quot;STL precio promedio&quot;) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## ℹ The deprecated feature was likely used in the forecast package. ## Please report the issue at &lt;https://github.com/robjhyndman/forecast/issues&gt;. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. El análisis de la serie temporal del precio promedio diario de Potato Red permitió evidenciar comportamientos consistentes con los fenómenos propios de los productos agrícolas de consumo masivo. En primer lugar, los gráficos de tendencia y promedios móviles muestran que los precios presentan fluctuaciones periódicas pero con una ligera tendencia creciente en el largo plazo. El promedio móvil de 7 días suaviza las variaciones diarias y deja entrever ciclos semanales asociados a la oferta en el mercado, mientras que el promedio de 30 días resalta un patrón más estructural que apunta a incrementos graduales, posiblemente relacionados con factores estacionales como la disponibilidad de cosecha o la variación de costos logísticos. El estudio de rezagos (lag 1, lag 7 y lag 30) refuerza esta observación: las gráficas de dispersión muestran una clara autocorrelación positiva, especialmente para rezagos cortos, indicando que los precios actuales dependen directamente de los valores recientes. Este comportamiento sugiere persistencia temporal: cuando los precios aumentan o disminuyen, tienden a mantener esa dirección durante varios días, lo cual es característico de mercados donde la información y las condiciones de oferta no cambian abruptamente. La función de autocorrelación (ACF) confirma esta dependencia temporal, con correlaciones significativas en los primeros rezagos que luego disminuyen de forma progresiva. Esto demuestra que la serie no sigue un comportamiento completamente aleatorio, sino que existen patrones repetitivos en el tiempo. La descomposición STL separó la serie en sus componentes de tendencia, estacionalidad y residuo. Los resultados muestran una estacionalidad marcada con ciclos anuales definidos: los precios tienden a elevarse en ciertas épocas del año y disminuir en otras, reflejando los periodos de cosecha y escasez. La tendencia general es estable con una leve inclinación al alza, mientras que los residuos mantienen una magnitud baja y no presentan patrones visibles, lo que indica que gran parte de la variabilidad del precio está explicada por la tendencia y la estacionalidad, sin presencia de choques exógenos significativos. En conjunto, estos hallazgos evidencian que la serie del precio promedio de Potato Red posee un comportamiento no estacionario, con una tendencia creciente y estacionalidad recurrente, pero sin irregularidades fuertes. El patrón identificado sugiere que los precios pueden modelarse de forma confiable mediante técnicas de suavizado exponencial o modelos ARIMA estacionales, una vez que se realicen las transformaciones necesarias para estabilizar la media y la varianza. En términos prácticos, los resultados reflejan que el mercado analizado responde a ciclos previsibles, lo cual facilita la planificación de precios, abastecimiento y estrategias de comercialización. 4.10 Estacionariedad y diferenciación Introducción En esta segunda parte se busca analizar si la serie de tiempo seleccionada (Potato Red) cumple con el supuesto de estacionariedad. Una serie estacionaria es aquella cuya media y varianza permanecen constantes en el tiempo. En caso de que no sea estacionaria, se aplicarán procedimientos de diferenciación # o transformación para estabilizar la tendencia y la variabilidad. # Usaremos una version &quot;limpia&quot; de la serie via interpolacion lineal base R, partimos de &#39;potatored&#39; (data.frame terminado) y/o de &#39;pot_ts&#39; (ts original) y &lt;- as.numeric(pot_ts) if (anyNA(y)) { idx_ok &lt;- which(!is.na(y)) y_interp &lt;- approx(x = idx_ok, y = y[idx_ok], xout = seq_along(y))$y } else { y_interp &lt;- y} pot_ts_clean &lt;- ts( y_interp, start = start(pot_ts), frequency = frequency(pot_ts) ) 4.11 Verificación de estacionariedad (ADF Test) # Prueba de raíz unitaria de Dickey-Fuller aumentada adf_result &lt;- adf.test(pot_ts_clean) adf_result ## ## Augmented Dickey-Fuller Test ## ## data: pot_ts_clean ## Dickey-Fuller = -3.0587, Lag order = 14, p-value = 0.1301 ## alternative hypothesis: stationary # al tener en el ADF inicial: p = 0.1301 → se concluye que es no estacionaria al nive, por lo cual procedemos con transformacion y diferenciacion en escalones # Serie base a usar en esta etapa y verificamos que no tenga na ni valores negativos y0 &lt;- pot_ts_clean sum(is.na(y0)) ## [1] 0 all(y0&gt;0) ## [1] TRUE y_log &lt;- log(y0) range(y0, na.rm = TRUE); range(y_log, na.rm = TRUE) # solo para verificar el cambio de escala ## [1] 15.0 113.5 ## [1] 2.708050 4.731803 adf_log &lt;- adf.test(y_log) adf_log$p.value ## [1] 0.1322035 La transformación logarítmica ayudó a homogeneizar la variabilidad, pero no eliminó la tendencia ni la dependencia temporal. La serie transformada sigue teniendo raíz unitaria, por lo que pasamos a una diferenciacion de primer orden (d=1) sobre la serie logaritmica y volvemos a probar estacionariedad. y_diff1 &lt;- diff(y_log, differences = 1) adf_diff1 &lt;- tseries::adf.test(na.omit(y_diff1)) ## Warning in tseries::adf.test(na.omit(y_diff1)): p-value smaller than printed ## p-value adf_diff1$p.value ## [1] 0.01 con este resultado podemos concluir que: La serie original no era estacionaria (p = 0.1301). La serie logarítmica tampoco lo fue (p = 0.1322), aunque esa transformación ayudó a estabilizar la varianza Al aplicar una diferencia de primer orden sobre la serie logarítmica, la prueba ADF arrojó p = 0.01, es decir &lt; 0.05, por lo tanto sí es estacionaria. 4.12 Interpretacion Luego de aplicar la transformación logarítmica, la serie mantuvo la misma tendencia general, por lo que no se logró estacionariedad. Sin embargo, al diferenciarla una vez (d = 1), la prueba de Dickey–Fuller aumentada mostró un p-valor de 0.01, lo que indica que se rechaza la hipótesis nula de raíz unitaria. En consecuencia, la serie diferenciada es estacionaria. Este resultado implica que la tendencia determinista fue eliminada mediante la primera diferencia, estabilizando la media a lo largo del tiempo. Por otro lado, la transformación logarítmica permitió controlar la heterocedasticidad, de modo que las fluctuaciones de la serie ahora son de magnitud comparable. La combinación de ambos pasos —logaritmo y diferencia de primer orden— produce una serie adecuada para modelar mediante métodos lineales, como los modelos ARIMA o SARIMA. Visualmente, la serie diferenciada oscila alrededor de cero y las funciones de autocorrelación (ACF y PACF) se estabilizan rápidamente, lo que refuerza la evidencia de estacionariedad. 4.13 AJUSTE DEL MODELO ARIMA Para seleccionar una especificación parsimoniosa se utilizó auto.arima(), que explora combinaciones de órdenes (,,) (p,d,q) y, cuando corresponde, (,,) (P,D,Q) estacionales, minimizando criterios de información como AIC (Akaike Information Criterion) y BIC (Bayesian Information Criterion). Previo al ajuste se evaluó la estacionariedad (prueba ADF), aplicando transformación logarítmica para estabilizar varianza y diferenciación de primer orden para remover tendencia cuando fue necesario. 4.14 Criterios de selección AIC penaliza menos la complejidad; útil para captar estructura. BIC penaliza más; favorece modelos más simples. Se eligió el modelo con AIC/BIC mínimos y residuos con comportamiento de ruido blanco. 4.15 Suavizamiento y Holt-Winters sobre la variable tiempo y_hw &lt;- na.interp(pot_ts) freq &lt;- frequency(y_hw) length(y_hw); freq ## [1] 2889 ## [1] 365 4.16 Particion de entrenamiento /prueba h_test &lt;- min(365, floor(length(y_hw)*0.2)) # 1 año o ~20% si no alcanza n &lt;- length(y_hw) y_train &lt;- window(y_hw, end = time(y_hw)[n - h_test]) y_test &lt;- window(y_hw, start = time(y_hw)[n - h_test + 1]) autoplot(y_hw) + geom_vline(xintercept = time(y_hw)[n - h_test + 1], linetype = 2) + labs(title = &quot;Serie completa con corte train/test&quot;, y = &quot;Precio promedio&quot;, x = &quot;Tiempo&quot;) + theme_minimal() ## Agregación semanal library(zoo) ## Warning: package &#39;zoo&#39; was built under R version 4.3.3 ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric # y_hw: serie ts diaria (freq=365) stopifnot(frequency(y_hw) %in% c(365, 366)) #secuencia de fechas real para la ts diaria tsp_hw &lt;- tsp(y_hw) # c(start, end, freq) start_year &lt;- floor(tsp_hw[1]) start_frac &lt;- tsp_hw[1] - start_year start_date &lt;- as.Date(paste0(start_year, &quot;-01-01&quot;)) + round(start_frac * 365.25) fechas_all &lt;- seq.Date(from = start_date, by = &quot;day&quot;, length.out = length(y_hw)) z_all &lt;- zoo(as.numeric(y_hw), fechas_all) #Agregar por semana calendario z_week &lt;- aggregate(z_all, as.Date(cut(index(z_all), &quot;week&quot;)), mean, na.rm = TRUE) #Convertimos a ts semanal (freq = 52) y_w &lt;- ts(as.numeric(z_week), frequency = 52) #Split train/test semanal h_test_w &lt;- min(52, floor(length(y_w) * 0.2)) n_w &lt;- length(y_w) y_train_w &lt;- window(y_w, end = time(y_w)[n_w - h_test_w]) y_test_w &lt;- window(y_w, start = time(y_w)[n_w - h_test_w + 1]) autoplot(y_w) + geom_vline(xintercept = time(y_w)[n_w - h_test_w + 1], linetype = 2) + labs(title = &quot;Serie semanal con corte train/test&quot;, y = &quot;Precio promedio semanal&quot;, x = &quot;Tiempo&quot;) + theme_minimal() 4.17 Modelos de suavizamiento y Holt-Winters en serie semanal # Horizonte de prueba h &lt;- length(y_test_w) # Modelos de suavizamiento base # Suavizamiento exponencial simple (SES) fit_ses_w &lt;- ets(y_train_w, model = &quot;ANN&quot;) fc_ses_w &lt;- forecast(fit_ses_w, h = h) # Holt: tendencia aditiva fit_holt_w &lt;- ets(y_train_w, model = &quot;AAN&quot;) fc_holt_w &lt;- forecast(fit_holt_w, h = h) # Holt-Winters con función base stats::HoltWinters fit_hwa_w &lt;- HoltWinters(y_train_w, seasonal = &quot;additive&quot;) fit_hwm_w &lt;- HoltWinters(y_train_w, seasonal = &quot;multiplicative&quot;) # Generar pronósticos a h pasos fc_hwa_w &lt;- forecast(fit_hwa_w, h = h) fc_hwm_w &lt;- forecast(fit_hwm_w, h = h) # Resumen de parámetros de suavizamiento pars_w &lt;- list( SES = fit_ses_w$par, Holt = fit_holt_w$par, HW_adi = fit_hwa_w$coefficients, HW_multi = fit_hwm_w$coefficients ) metodos_w &lt;- c( SES = fit_ses_w$method, Holt = fit_holt_w$method, HW_adi = &quot;Holt-Winters aditivo (HoltWinters)&quot;, HW_mul = &quot;Holt-Winters multiplicativo (HoltWinters)&quot; ) list(pars = pars_w, metodos = metodos_w) ## $pars ## $pars$SES ## alpha l ## 0.9998999 20.0661412 ## ## $pars$Holt ## alpha beta phi l b ## 0.9998998 0.1131366 0.8000015 19.3507661 0.7318030 ## ## $pars$HW_adi ## a b s1 s2 s3 s4 ## 39.08244375 0.07882721 -7.65617219 -5.33129937 -2.12172776 -0.60521373 ## s5 s6 s7 s8 s9 s10 ## 1.67227131 3.70855086 3.86297747 4.29730738 4.70950257 5.51286110 ## s11 s12 s13 s14 s15 s16 ## 6.58108183 9.34052131 11.67282675 11.56985459 10.72690049 10.62915737 ## s17 s18 s19 s20 s21 s22 ## 11.56624926 14.32396189 12.96493891 12.91210622 15.60833595 19.70484488 ## s23 s24 s25 s26 s27 s28 ## 18.21542017 15.04288451 8.57289145 4.41893044 3.59468994 2.26948285 ## s29 s30 s31 s32 s33 s34 ## 1.41348224 1.16589200 0.07345107 -2.59161738 -5.38569070 -6.81747767 ## s35 s36 s37 s38 s39 s40 ## -8.35116126 -10.31002086 -14.36805886 -15.48013931 -13.59119371 -14.10375330 ## s41 s42 s43 s44 s45 s46 ## -12.98609882 -13.91879059 -12.80762063 -12.45344901 -10.91079687 -9.50278976 ## s47 s48 s49 s50 s51 s52 ## -7.48181474 -7.63951511 -9.66359895 -9.41494901 -8.19836375 -8.36815804 ## ## $pars$HW_multi ## a b s1 s2 s3 s4 ## 40.06957603 0.07882721 0.78984647 0.86149189 0.95592829 0.99520880 ## s5 s6 s7 s8 s9 s10 ## 1.06150922 1.11859277 1.10742123 1.11547832 1.13362719 1.15295252 ## s11 s12 s13 s14 s15 s16 ## 1.19755872 1.28051297 1.34512974 1.33136792 1.29845693 1.29564795 ## s17 s18 s19 s20 s21 s22 ## 1.31337013 1.37966490 1.36129664 1.37542631 1.45910223 1.55273805 ## s23 s24 s25 s26 s27 s28 ## 1.49801968 1.41880910 1.25803359 1.12986066 1.10809063 1.06878253 ## s29 s30 s31 s32 s33 s34 ## 1.05012792 1.03448499 1.00251606 0.92562241 0.84794487 0.78549769 ## s35 s36 s37 s38 s39 s40 ## 0.73966473 0.68969443 0.59218461 0.55743071 0.58537805 0.58407654 ## s41 s42 s43 s44 s45 s46 ## 0.61227139 0.60444293 0.63415394 0.64018299 0.67488001 0.72564177 ## s47 s48 s49 s50 s51 s52 ## 0.78927007 0.78769837 0.73692250 0.74269354 0.77194581 0.76652385 ## ## ## $metodos ## SES ## &quot;ETS(A,N,N)&quot; ## Holt ## &quot;ETS(A,Ad,N)&quot; ## HW_adi ## &quot;Holt-Winters aditivo (HoltWinters)&quot; ## HW_mul ## &quot;Holt-Winters multiplicativo (HoltWinters)&quot; 4.18 Comparación de presición fuera de muestra # Calcular métricas de error para cada modelo en el conjunto de prueba acc_tbl &lt;- bind_rows( data.frame(model = &quot;SES&quot;, accuracy(fc_ses_w, y_test_w)), data.frame(model = &quot;Holt&quot;, accuracy(fc_holt_w, y_test_w)), data.frame(model = &quot;HW_adi&quot;, accuracy(fc_hwa_w, y_test_w)), data.frame(model = &quot;HW_mul&quot;, accuracy(fc_hwm_w, y_test_w)) ) %&gt;% select(model, RMSE, MAE, MAPE) acc_tbl ## model RMSE MAE MAPE ## Training set...1 SES 2.929804 1.928708 5.748854 ## Test set...2 SES 33.778723 24.276695 34.505452 ## Training set...3 Holt 2.902352 1.901817 5.638535 ## Test set...4 Holt 34.593228 24.973105 35.456690 ## Training set...5 HW_adi 2.984060 2.102575 6.453931 ## Test set...6 HW_adi 20.668712 14.555681 20.798164 ## Training set...7 HW_mul 2.846973 1.996849 6.036061 ## Test set...8 HW_mul 18.997168 13.487363 19.577035 El modelo Holt-Winters multiplicativo (HW_mul) es el mejor, porque presenta los errores más bajos (RMSE y MAPE) en la ventana de prueba. Esto indica que la estacionalidad es proporcional al nivel de la serie (los picos crecen cuando el nivel general sube), lo cual es consistente con lo que se veia en el grafico. 4.19 Diagnostico de residuos Vamos a confirmar que los residuos del modelo ganador (HW multiplicativo) se comportan como ruido blanco best_fc &lt;- fc_hwm_w # ganador: Holt-Winters multiplicativo checkresiduals(best_fc$model) ## ## Ljung-Box test ## ## data: Residuals from HoltWinters ## Q* = 76.422, df = 62, p-value = 0.1029 ## ## Model df: 0. Total lags used: 62 Al comparar los modelos de suavizamiento, Holt y Holt-Winters, se encontró que el Holt-Winters multiplicativo obtuvo los mejores resultados en la ventana de prueba, con los menores valores de RMSE (18.99) y MAPE (19.57 %). Esto indica que la serie presenta una estacionalidad proporcional al nivel, es decir, las fluctuaciones son más amplias cuando los valores son altos. El análisis de residuos respalda la adecuación del modelo: el p-valor = 0.1029 del test de Ljung-Box confirma que no existe autocorrelación significativa (residuos ≈ ruido blanco). Por tanto, el modelo Holt-Winters multiplicativo logra capturar adecuadamente la tendencia y la estacionalidad de la serie semanal del precio promedio del Potato Red. 4.20 Pronostico final # Reentrenar el modelo Holt-Winters multiplicativo con toda la serie semanal fit_final_hw &lt;- HoltWinters(y_w, seasonal = &quot;multiplicative&quot;) # pronóstico a 52 semanas (≈ 1 año) h_future &lt;- 52 fc_final_hw &lt;- forecast(fit_final_hw, h = h_future) # Visualizacion del pronóstico final autoplot(fc_final_hw) + labs( title = &quot;Pronostico final Holt-Winters multiplicativo (52 semanas)&quot;, y = &quot;Precio promedio semanal&quot;, x = &quot;Tiempo&quot; ) + theme_minimal() # primeras filas de la tabla de pronostico head(data.frame( Semana = time(fc_final_hw$mean), Pronostico = round(as.numeric(fc_final_hw$mean), 2), LI_80 = round(fc_final_hw$lower[,1], 2), LS_80 = round(fc_final_hw$upper[,1], 2), LI_95 = round(fc_final_hw$lower[,2], 2), LS_95 = round(fc_final_hw$upper[,2], 2) ), 10) ## Semana Pronostico LI_80 LS_80 LI_95 LS_95 ## 1 8.961538 37.69 33.31 42.07 30.99 44.39 ## 2 8.980769 40.88 35.05 46.72 31.96 49.81 ## 3 9.000000 45.08 37.83 52.33 33.99 56.16 ## 4 9.019231 47.46 39.09 55.83 34.66 60.26 ## 5 9.038462 50.77 41.19 60.34 36.13 65.41 ## 6 9.057692 55.25 44.31 66.19 38.52 71.98 ## 7 9.076923 55.96 44.35 67.58 38.20 73.73 ## 8 9.096154 55.31 43.30 67.32 36.95 73.67 ## 9 9.115385 55.66 43.09 68.24 36.43 74.90 ## 10 9.134615 58.37 44.76 71.99 37.55 79.20 4.21 Conclusiones Tras evaluar diferentes métodos de suavizamiento exponencial, se determinó que el modelo Holt-Winters multiplicativo fue el que presentó el mejor desempeño predictivo, con los menores errores (RMSE = 18.99 y MAPE = 19.6 %) en la ventana de prueba. Este resultado confirma que la serie presenta estacionalidad proporcional al nivel, es decir, cuando el precio promedio del Potato Red aumenta, las fluctuaciones también lo hacen en la misma proporción. Los residuos del modelo no mostraron autocorrelación significativa (p-valor = 0.1029), por lo que se concluye que el modelo explica adecuadamente la estructura temporal. Con la serie completa y el modelo reentrenado, el pronóstico a 52 semanas muestra una tendencia oscilante con picos regulares y amplitud similar a la observada históricamente. Las bandas de confianza (80 % y 95 %) reflejan un nivel de incertidumbre moderado, lo que otorga confianza en las estimaciones. En conjunto, el método Holt-Winters multiplicativo demuestra ser una herramienta sólida y confiable para proyectar el comportamiento estacional del precio semanal del Potato Red. 4.22 Desarrollo metodológico y justificación de decisiones El proceso de aplicación del modelo de Holt-Winters a la serie de tiempo del precio promedio del Potato Red implicó diversos ajustes metodológicos debido a las características particulares de los datos. La variable de estudio correspondía a una serie diaria con una extensión superior a 2800 observaciones y frecuencia anual de 365. Si bien esta cantidad de datos representaba una fuente valiosa de información, también generó limitaciones computacionales al momento de ajustar modelos estacionales como ets(model = \"AAA\") o hw(seasonal = \"additive\"), debido a que la función ets() no está optimizada para manejar estacionalidades tan largas. Durante los primeros intentos, el software arrojó el error “Frequency too high” o se quedaba ejecutando indefinidamente. Esto motivó una revisión del enfoque, identificando que la estacionalidad de interés no necesariamente se presentaba de manera diaria, sino más bien en ciclos semanales o mensuales, propios de los precios agrícolas. 4.23 Ajuste de la frecuencia temporal Como solución, se decidió agregar la serie a frecuencia semanal, calculando el promedio de los precios diarios. Esta decisión permitió conservar la forma cíclica de la serie (picos y valles regulares) y, al mismo tiempo, reducir la frecuencia de 365 a 52, lo cual hizo posible aplicar modelos estacionales de forma estable y con un tiempo de cómputo razonable. En la práctica, esto significó reconstruir la serie con una frecuencia semanal (frequency = 52), evitando la sobrecarga que impedía el ajuste de Holt-Winters en la versión original. 4.24 Modelos aplicados Una vez ajustada la frecuencia, se implementaron cuatro modelos de suavizamiento: Suavizamiento exponencial simple (SES) – Captura únicamente el nivel de la serie. Método de Holt – Incorpora tendencia aditiva. Holt-Winters aditivo – Considera tendencia y estacionalidad de amplitud constante. Holt-Winters multiplicativo – Considera estacionalidad proporcional al nivel. Debido a los errores recurrentes con ets() y hw(), se optó finalmente por la función stats::HoltWinters(), que permite ajustar modelos estacionales de manera más estable con series largas o de alta frecuencia. 4.25 Validación del modelo La serie semanal se dividió en un conjunto de entrenamiento (80%) y otro de prueba (20%), correspondiente aproximadamente a un año de observaciones. Con esta división, se evaluó el desempeño predictivo de cada modelo mediante métricas como RMSE, MAE y MAPE. Los resultados mostraron que el modelo Holt-Winters multiplicativo presentó el mejor desempeño (RMSE = 18.99, MAPE = 19.6%), superando a las versiones aditiva, Holt y SES. Esto indica que la estacionalidad es proporcional al nivel de la serie: cuando los precios son altos, las fluctuaciones semanales también lo son. 4.26 Diagnóstico de residuos Para validar el ajuste, se analizaron los residuos del modelo Holt-Winters multiplicativo. El test de Ljung-Box (p-valor = 0.1029) indicó ausencia de autocorrelación significativa, lo cual demuestra que el modelo logra capturar adecuadamente la tendencia y la estacionalidad de los datos. Además, el gráfico ACF de los residuos no mostró patrones sistemáticos, confirmando que el error se comporta como ruido blanco. 4.27 Pronóstico final Con base en el modelo seleccionado, se reentrenó la serie completa y se realizó un pronóstico a 52 semanas (equivalente a un año). El resultado mostró una evolución oscilante, con picos estacionales regulares y una amplitud coherente con los patrones históricos observados. Las bandas de confianza del 80% y 95% se mantuvieron en rangos moderados, reflejando un nivel de incertidumbre aceptable. 4.28 Conclusión integradora En síntesis, el desarrollo de este modelo implicó un proceso iterativo de ajuste y validación. Se comprobó que aplicar Holt-Winters directamente sobre la serie diaria era impracticable por su frecuencia alta, por lo que fue necesario agregar la serie a frecuencia semanal para estabilizar el modelo. Este cambio permitió aplicar el método de forma exitosa y obtener resultados coherentes, concluyendo que el modelo Holt-Winters multiplicativo es una herramienta sólida para pronosticar el comportamiento estacional del precio del Potato Red, combinando buena precisión y consistencia temporal. 4.29 Ajuste e interpretación del modelo ARIMA/SARIMA - Box-Jenkins (ARIMA) # Serie semanal en log y_w_log &lt;- log(y_w) y_train_w_log &lt;- log(y_train_w) y_test_w_log &lt;- log(y_test_w) # Horizonte h &lt;- length(y_test_w) lengths &lt;- c(total = length(y_w_log), train = length(y_train_w_log), test = length(y_test_w)) lengths ## total train test ## 414 362 52 ggAcf(y_train_w_log) + labs(title = &quot;ACF log semanal (train)&quot;) ggPacf(y_train_w_log) + labs(title = &quot;PACF log semanal (train)&quot;) # Candidato 1: ARIMA no estacional fit_ns &lt;- auto.arima( y_train_w_log, seasonal = FALSE, stepwise = TRUE, approximation = TRUE, allowmean = TRUE, allowdrift = TRUE ) # Candidato 2: m &lt;- frequency(y_train_w_log) D_est &lt;- nsdiffs(y_train_w_log) y_train_w_log_sdiff &lt;- diff(y_train_w_log, lag = m, differences = D_est) fit_seas_fast &lt;- auto.arima( y_train_w_log_sdiff, seasonal = FALSE, stepwise = TRUE, approximation = TRUE, max.p = 5, max.q = 5, max.order = 8, allowmean = TRUE, allowdrift = TRUE ) fit_seas_fast ## Series: y_train_w_log_sdiff ## ARIMA(1,0,0) with zero mean ## ## Coefficients: ## ar1 ## 0.9562 ## s.e. 0.0163 ## ## sigma^2 = 0.009812: log likelihood = 276.14 ## AIC=-548.29 AICc=-548.25 BIC=-540.82 # Extraer orden no estacional del modelo rapido sobre la serie s-diferenciada ord &lt;- arimaorder(fit_seas_fast) p &lt;- ord[&quot;p&quot;]; d &lt;- 0; q &lt;- ord[&quot;q&quot;] # Periodo estacional y orden estacional detectado m &lt;- frequency(y_train_w_log) D_est &lt;- nsdiffs(y_train_w_log) # Ajuste SARIMA equivalente sobre la serie en log SIN diferenciar manualmente # SARIMA(p,d,q)(P=0, D=D_est, Q=0)[m], sin media (zero mean) como indico el modelo rapido fit_seas_refit &lt;- Arima( y_train_w_log, order = c(p, d, q), seasonal = list(order = c(0, D_est, 0), period = m), include.mean = FALSE ) fit_seas_refit ## Series: y_train_w_log ## ARIMA(1,0,0)(0,1,0)[52] ## ## Coefficients: ## ar1 ## 0.9562 ## s.e. 0.0163 ## ## sigma^2 = 0.009814: log likelihood = 276.15 ## AIC=-548.3 AICc=-548.26 BIC=-540.82 4.30 Pronostico a h pasos y metricas RMSE/MAE/MAPE # 1) Pronostico en log y transformacion a escala original h &lt;- length(y_test_w) fc_seas_log &lt;- forecast(fit_seas_refit, h = h) fc_seas &lt;- fc_seas_log fc_seas$mean &lt;- exp(fc_seas_log$mean) fc_seas$lower &lt;- exp(fc_seas_log$lower) fc_seas$upper &lt;- exp(fc_seas_log$upper) # 2) Comparacion tiene_ns &lt;- exists(&quot;fc_ns&quot;) if (tiene_ns) { acc_tbl_arima &lt;- bind_rows( data.frame(model = &quot;ARIMA_ns&quot;, accuracy(fc_ns, y_test_w)), data.frame(model = &quot;SARIMA_52&quot;, accuracy(fc_seas, y_test_w)) ) %&gt;% select(model, RMSE, MAE, MAPE) } else { acc_tbl_arima &lt;- bind_rows( data.frame(model = &quot;SARIMA_52&quot;, accuracy(fc_seas, y_test_w)) ) %&gt;% select(model, RMSE, MAE, MAPE) } acc_tbl_arima ## model RMSE MAE MAPE ## Training set SARIMA_52 0.09152501 0.06528711 1.90487 ## Test set SARIMA_52 18.80827374 15.08098880 25.67046 4.31 Diagnostico de residuos # Evaluacion de residuos del modelo SARIMA checkresiduals(fit_seas_refit) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,0,0)(0,1,0)[52] ## Q* = 152.72, df = 71, p-value = 6.441e-08 ## ## Model df: 1. Total lags used: 72 4.32 Pronostico final Sarima (1,0,0)(0,1,0)[52] # Pronostico a 52 semanas fc_final &lt;- forecast(fit_seas_refit, h = 52) # Volver a escala original fc_final_exp &lt;- fc_final fc_final_exp$mean &lt;- exp(fc_final$mean) fc_final_exp$lower &lt;- exp(fc_final$lower) fc_final_exp$upper &lt;- exp(fc_final$upper) fc_final_exp$x &lt;- exp(fc_final_exp$x) # --------------------------------- # OPCION A: Grafico simple del pronostico (AHORA SERÁ COHERENTE) autoplot(fc_final_exp) + labs( title = &quot;Pronostico final SARIMA(1,0,0)(0,1,0)[52]&quot;, subtitle = &quot;Proyeccion de precios semanales (Escala Original)&quot;, x = &quot;Tiempo&quot;, y = &quot;Precio promedio semanal&quot; ) + theme_minimal() # Ajuste automático con comparación AIC/BIC y &lt;- ts(potatored$Average, frequency = 7) fit_arima &lt;- forecast::auto.arima( y, seasonal = TRUE, stepwise = FALSE, approximation = FALSE ) fit_arima ## Series: y ## ARIMA(1,1,0) ## ## Coefficients: ## ar1 ## -0.2051 ## s.e. 0.0190 ## ## sigma^2 = 4.054: log likelihood = -5848.36 ## AIC=11700.72 AICc=11700.73 BIC=11712.66 AIC(fit_arima); BIC(fit_arima) ## [1] 11700.72 ## [1] 11712.56 4.33 Interpretación del modelo Los parámetros estimados (,,) (p,d,q) reflejan la dependencia autorregresiva y el componente de promedio móvil, ambos esenciales para capturar la dinámica de corto plazo de la serie. El parámetro d —y  D si se incluye una componente estacional— controla la diferenciación aplicada para garantizar la estacionariedad de la media, permitiendo que la serie cumpla los supuestos de los modelos lineales autorregresivos. En este contexto, los valores obtenidos evidencian una estructura temporal que combina persistencia en los precios con fluctuaciones regulares atribuibles a factores estacionales. 4.34 Reflexión y justificación del proceso Box–Jenkins En esta fase se implementó la metodología Box–Jenkins con el propósito de identificar un modelo autorregresivo e integrado de medias móviles (ARIMA) que representara adecuadamente la dinámica temporal del precio promedio semanal del Potato Red y permitiera realizar pronósticos confiables a corto y mediano plazo. Se inició el proceso con una transformación logarítmica de la serie semanal, buscando estabilizar la varianza y cumplir con los supuestos de linealidad. Posteriormente, se determinó la necesidad de aplicar una diferencia estacional de orden 1, identificada mediante la función nsdiffs() y la prueba OCSB, que confirmó una estacionalidad anual de 52 semanas. Este paso fue crucial para asegurar la estacionariedad de la serie antes del ajuste final de los modelos ARIMA y SARIMA, condición indispensable dentro del enfoque Box–Jenkins. 4.35 Ajustes metodológicos y rendimiento computacional Durante la primera ejecución de auto.arima() con búsqueda estacional completa, se observó que el proceso requería un tiempo computacional elevado, consecuencia directa de la longitud de la serie y del gran número de combinaciones posibles entre parámetros. Para optimizar el rendimiento y mantener la rigurosidad estadística, se desarrolló una estrategia de ajuste en dos etapas complementarias: Primera etapa: Se modeló la serie ya diferenciada estacionalmente (y_train_w_log_sdiff) sin incluir la componente estacional explícita. Este enfoque permitió acelerar la búsqueda y obtener una estructura preliminar AR(1) con coeficiente φ ≈ 0.956, evidenciando la dependencia dominante sin saturar los recursos computacionales. Segunda etapa: Se refinó el modelo, ajustando la serie logarítmica original e incorporando la estacionalidad detectada, obteniendo finalmente el modelo SARIMA(1,0,0)(0,1,0)[52]. Este procedimiento permitió mantener la coherencia metodológica del enfoque Box–Jenkins, optimizando la eficiencia y la reproducibilidad del proceso analítico. 4.36 Evaluación del modelo El modelo SARIMA(1,0,0)(0,1,0)[52] mostró un excelente ajuste dentro de muestra (MAPE ≈ 1.9 %) y un desempeño razonable fuera de muestra (MAPE ≈ 25.7 %). El coeficiente AR(1), cercano a 1, evidencia una alta persistencia temporal, indicando que los precios semanales del Potato Red dependen fuertemente de los valores previos. Al analizar los residuos mediante checkresiduals(), la prueba de Ljung–Box arrojó un p-valor &lt; 0.05, lo que sugiere la presencia de autocorrelación remanente. Este hallazgo abre la posibilidad de incorporar términos adicionales —por ejemplo, un componente MA o parámetros estacionales extra— para capturar dependencias de mayor orden. Aun así, los residuos no mostraron tendencias sistemáticas ni heterocedasticidad marcada, indicando un buen ajuste general del modelo y un comportamiento próximo al ruido blanco. 4.37 Reflexión metodológica final La aplicación del enfoque Box–Jenkins permitió equilibrar rigor estadístico y eficiencia computacional, demostrando que, incluso en series extensas con fuerte estacionalidad, es posible construir modelos parsimoniosos, interpretables y funcionales. Este proceso refuerza la importancia de documentar y justificar cada decisión metodológica, desde la transformación logarítmica hasta la diferenciación y la selección del modelo final. El modelo obtenido captura adecuadamente la tendencia y la estacionalidad del precio semanal del Potato Red, proporcionando una base sólida para pronósticos confiables. Se concluye que este tipo de modelado contribuye de manera significativa a la planificación de abastecimiento y estrategias de fijación de precios agrícolas, ofreciendo un soporte cuantitativo a la toma de decisiones. 4.38 EVALUACIÓN DEL MODELO La validación se centró en tres frentes: 4.1 Diagnóstico de residuos: ausencia de autocorrelación (ACF/PACF de residuos sin picos significativos), media cercana a cero y homocedasticidad razonable. 4.2 Criterios de información: AIC/BIC del modelo final comparados con alternativas cercanas (p.ej., variaciones de p, q o componente estacional). 4.3 Error de pronóstico (si se dispone de holdout): métricas como RMSE, MAE y MAPE sobre un conjunto de prueba temporal. Conclusión de evaluación. El modelo seleccionado mostró residuos compatibles con ruido blanco y valores de AIC/BIC competitivos, lo que sugiere ajuste adecuado sin sobreparametrización. En presencia de estacionalidad pronunciada, un SARIMA suele mejorar aún más AIC/BIC y diagnóstico residual. 4.39 PRONOSTICO Y CONCLUSIONES Con el modelo validado, se generaron pronósticos puntuales e intervalares mediante forecast() (o predict()), a un horizonte operativo (p.ej., 30 días). Los intervalos de confianza reflejan la incertidumbre asociada a la varianza del error y a la propagación en el tiempo. Pronóstico final h &lt;- 30 fc &lt;- forecast::forecast(fit_arima, h = h) fc ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 413.7143 36 33.41964 38.58036 32.05368 39.94632 ## 413.8571 36 32.70369 39.29631 30.95873 41.04127 ## 414.0000 36 32.05918 39.94082 29.97304 42.02696 ## 414.1429 36 31.51683 40.48317 29.14359 42.85641 ## 414.2857 36 31.03139 40.96861 28.40117 43.59883 ## 414.4286 36 30.58970 41.41030 27.72566 44.27434 ## 414.5714 36 30.18137 41.81863 27.10118 44.89882 ## 414.7143 36 29.79989 42.20011 26.51775 45.48225 ## 414.8571 36 29.44055 42.55945 25.96819 46.03181 ## 415.0000 36 29.09991 42.90009 25.44722 46.55278 ## 415.1429 36 28.77530 43.22470 24.95078 47.04922 ## 415.2857 36 28.46467 43.53533 24.47571 47.52429 ## 415.4286 36 28.16635 43.83365 24.01946 47.98054 ## 415.5714 36 27.87897 44.12103 23.57996 48.42004 ## 415.7143 36 27.60143 44.39857 23.15549 48.84451 ## 415.8571 36 27.33276 44.66724 22.74461 49.25539 ## 416.0000 36 27.07218 44.92782 22.34608 49.65392 ## 416.1429 36 26.81899 45.18101 21.95886 50.04114 ## 416.2857 36 26.57260 45.42740 21.58204 50.41796 ## 416.4286 36 26.33249 45.66751 21.21482 50.78518 ## 416.5714 36 26.09819 45.90181 20.85650 51.14350 ## 416.7143 36 25.86932 46.13068 20.50646 51.49354 ## 416.8571 36 25.64550 46.35450 20.16416 51.83584 ## 417.0000 36 25.42642 46.57358 19.82910 52.17090 ## 417.1429 36 25.21179 46.78821 19.50085 52.49915 ## 417.2857 36 25.00134 46.99866 19.17900 52.82100 ## 417.4286 36 24.79485 47.20515 18.86320 53.13680 ## 417.5714 36 24.59209 47.40791 18.55311 53.44689 ## 417.7143 36 24.39287 47.60713 18.24843 53.75157 ## 417.8571 36 24.19702 47.80298 17.94890 54.05110 4.40 CONCLUSIONES GENERALES FINALES La serie del “Potato Red” presenta no estacionariedad inicial (tendencia y estacionalidad), que se corrige con log + diferenciación. La dependencia temporal y la estacionalidad justifican el uso de ARIMA/SARIMA. El modelo seleccionado vía AIC/BIC exhibe residuos tipo ruido blanco y métricas de error razonables, lo que respalda su uso para planificación de abastecimiento y precios. Recomendaciones: evaluar SARIMA si la estacionalidad es fuerte, comparar con ETS y considerar ARIMAX si se dispone de variables exógenas (oferta, clima, transporte). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
