[["index.html", "Series de Tiempo - Predicción de Precios de Frutas y Verduras en Nepal Capítulo 1 Introducción", " Series de Tiempo - Predicción de Precios de Frutas y Verduras en Nepal Grupo 2 2025-10-26 Capítulo 1 Introducción Time Series Price Vegetables and Fruits El conjunto de datos “Time Series Price Vegetables and Fruits” contiene información oficial sobre los precios diarios de las principales frutas y verduras en Nepal entre 2013 y 2021 de una fuente oficial del gobierno (Kalimati), compilada en un repositorio público Kaggle. Commodity: Nombre de las frutas o vegetales Date: Fecha en formato año - mes – día Unit: Unidad de medida (Kg) Minimum: Precio mínimo registrado de venta del día Maximum: Precio máximo registrado de venta del día Average: Precio promedio de venta del día Analizar y predecir el precio de productos agrícolas es fundamental para poder tomar decisiones informadas, asignar los recursos de una manera óptima y contribuir al crecimiento económico del agro. Por la dinámica de los precios en frutas y verduras, que se encuentra condicionada por temporadas de cosecha, factores climáticos y la relación entre oferta y demanda, resulta complejo proyectar precios de manera certera. Con modelos tradicionales de análisis, captar patrones puede ser difícil; sin embargo, esta limitación puede superarse mediante técnicas de machine learning aplicadas a series de tiempo. La selección del dataset se debe al carácter temporal y a la granularidad de los datos, lo que facilita hallar tendencias y estacionalidades en los precios, emplear datos históricos para predecir precios futuros, así como detectar patrones inusuales o anomalías en los datos. Otro valor importante que puede lograrse a través del análisis del conjunto de datos es el desarrollo de estrategias de precios basadas en los patrones hallados. "],["eda-y-análisis-de-series-de-tiempo.html", "Capítulo 2 EDA y Análisis de Series de tiempo 2.1 Analisis de series de tiempo", " Capítulo 2 EDA y Análisis de Series de tiempo 2.0.1 Cargue de Datos # Librerias (base originales + necesarias) library(readr) library(dplyr) library(lubridate) library(ggplot2) library(forecast) library(tseries) library(here) # rutas reproducibles library(tidyr) # regularizar fechas (complete) library(slider) # promedios moviles Realizaremos nuestro analisis con un conjunto de datos de precios agrícolas proveniente del mercado de Kalimati (Nepal). Este dataset incluye información diaria sobre productos agrícolas, sus precios mínimos, máximos y promedio. A partir de estos datos se realizará un análisis exploratorio y un estudio de comportamiento temporal de los precios. csv_file &lt;- &quot;C:/Users/Steba/OneDrive/Escritorio/kalimati_tarkari_dataset (2).csv&quot; # Leer datos data_raw &lt;- readr::read_csv(csv_file, show_col_types = FALSE) # Estandarizar nombres a snake para facilitar mapeo nms &lt;- tolower(gsub(&quot;[^a-zA-Z0-9]+&quot;, &quot;_&quot;, names(data_raw))) # Intentar mapear columnas canonicas (Commodity / Date / Minimum / Maximum / Average) df &lt;- data_raw names(df) &lt;- nms # Mapeo flexible (case-insensitive) pick_first &lt;- function(cands) { hit &lt;- intersect(cands, names(df)) if (length(hit) == 0) return(NA_character_) else return(hit[1]) } col_commodity &lt;- pick_first(c(&quot;commodity&quot;,&quot;item&quot;,&quot;product&quot;,&quot;variety&quot;,&quot;name&quot;)) col_date &lt;- pick_first(c(&quot;date&quot;,&quot;fecha&quot;,&quot;day&quot;)) col_min &lt;- pick_first(c(&quot;minimum&quot;,&quot;min&quot;,&quot;min_price&quot;,&quot;price_min&quot;)) col_max &lt;- pick_first(c(&quot;maximum&quot;,&quot;max&quot;,&quot;max_price&quot;,&quot;price_max&quot;)) col_avg &lt;- pick_first(c(&quot;average&quot;,&quot;avg&quot;,&quot;avg_price&quot;,&quot;price_avg&quot;,&quot;mean_price&quot;)) req &lt;- c(col_commodity, col_date, col_min, col_max, col_avg) if (any(is.na(req))) { stop(&quot;No fue posible mapear columnas clave (commodity/date/min/max/average). Revisa nombres del CSV: &quot;, paste(names(df), collapse = &quot;, &quot;)) } data &lt;- df %&gt;% transmute( Commodity = .data[[col_commodity]], Date = as.Date(.data[[col_date]]), Unit = NA_character_, # si no existe, queda NA (no se usa en el analisis) Minimum = as.numeric(.data[[col_min]]), Maximum = as.numeric(.data[[col_max]]), Average = as.numeric(.data[[col_avg]]) ) # Chequeos basicos stopifnot(inherits(data$Date, &quot;Date&quot;)) 2.0.2 Primera Visualización de los datos # Vista previa y estructura head(data) ## # A tibble: 6 × 6 ## Commodity Date Unit Minimum Maximum Average ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Tomato Big(Nepali) 2013-06-16 &lt;NA&gt; 35 40 37.5 ## 2 Tomato Small(Local) 2013-06-16 &lt;NA&gt; 26 32 29 ## 3 Potato Red 2013-06-16 &lt;NA&gt; 20 21 20.5 ## 4 Potato White 2013-06-16 &lt;NA&gt; 15 16 15.5 ## 5 Onion Dry (Indian) 2013-06-16 &lt;NA&gt; 28 30 29 ## 6 Carrot(Local) 2013-06-16 &lt;NA&gt; 30 35 32.5 str(data) ## tibble [197,161 × 6] (S3: tbl_df/tbl/data.frame) ## $ Commodity: chr [1:197161] &quot;Tomato Big(Nepali)&quot; &quot;Tomato Small(Local)&quot; &quot;Potato Red&quot; &quot;Potato White&quot; ... ## $ Date : Date[1:197161], format: &quot;2013-06-16&quot; &quot;2013-06-16&quot; ... ## $ Unit : chr [1:197161] NA NA NA NA ... ## $ Minimum : num [1:197161] 35 26 20 15 28 30 6 30 35 25 ... ## $ Maximum : num [1:197161] 40 32 21 16 30 35 10 35 40 30 ... ## $ Average : num [1:197161] 37.5 29 20.5 15.5 29 32.5 8 32.5 37.5 27.5 ... summary(data) ## Commodity Date Unit Minimum ## Length:197161 Min. :2013-06-16 Length:197161 Min. : 1.00 ## Class :character 1st Qu.:2015-08-24 Class :character 1st Qu.: 40.00 ## Mode :character Median :2017-08-03 Mode :character Median : 60.00 ## Mean :2017-08-09 Mean : 85.42 ## 3rd Qu.:2019-08-27 3rd Qu.: 100.00 ## Max. :2021-05-13 Max. :1800.00 ## Maximum Average ## Min. : 6.00 Min. : 5.00 ## 1st Qu.: 45.00 1st Qu.: 42.50 ## Median : 70.00 Median : 65.00 ## Mean : 94.16 Mean : 89.79 ## 3rd Qu.: 110.00 3rd Qu.: 105.00 ## Max. :2000.00 Max. :1900.00 2.0.3 Datos faltantes y duplicados # NAs y duplicados generales sum(is.na(data)) ## [1] 197161 sum(duplicated(data)) ## [1] 0 2.0.4 Análisis Univariado #analisis univariado ggplot(data, aes(x = Average)) + geom_histogram(binwidth = 5, fill = &quot;blue&quot;, color = &quot;black&quot;, alpha = 0.7) + labs(title = &quot;Distribucion de Precios Promedio&quot;, x = &quot;Precio Promedio&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() data %&gt;% summarise( Mean = mean(Average, na.rm = TRUE), Median = median(Average, na.rm = TRUE), SD = sd(Average, na.rm = TRUE), Min = min(Average, na.rm = TRUE), Max = max(Average, na.rm = TRUE) ) ## # A tibble: 1 × 5 ## Mean Median SD Min Max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 89.8 65 79.6 5 1900 2.0.5 Análisis Bivariado #analisis bivariado ggplot(data, aes(x = Minimum, y = Maximum)) + geom_point(alpha = 0.5) + labs(title = &quot;Relacion entre Precio Minimo y Maximo&quot;, x = &quot;Precio Minimo&quot;, y = &quot;Precio Maximo&quot;) + theme_minimal() 2.0.6 Correlación de los datos cor(data$Minimum, data$Maximum, use = &quot;complete.obs&quot;) ## [1] 0.9950614 2.1 Analisis de series de tiempo if (&quot;Potato Red&quot; %in% unique(data$Commodity)) { target_item &lt;- &quot;Potato Red&quot; } else { target_item &lt;- data %&gt;% count(Commodity, sort = TRUE) %&gt;% slice(1) %&gt;% pull(Commodity) } target_item ## [1] &quot;Potato Red&quot; # Filtrar y regularizar serie diaria potatored &lt;- data %&gt;% filter(Commodity == target_item) %&gt;% select(Date, Average) %&gt;% group_by(Date) %&gt;% summarise(Average = mean(Average), .groups = &quot;drop&quot;) %&gt;% complete(Date = seq(min(Date, na.rm = TRUE), max(Date, na.rm = TRUE), by = &quot;day&quot;)) %&gt;% arrange(Date) # Construir objeto ts (diario, 365) pot_ts &lt;- ts( potatored$Average, start = c(lubridate::year(min(potatored$Date, na.rm = TRUE)), lubridate::yday(min(potatored$Date, na.rm = TRUE))), frequency = 365 ) 2.1.1 Serie basica y ACF autoplot(pot_ts) + labs(title = &quot;Serie de tiempo: precio promedio&quot;, y = &quot;Precio promedio&quot;) + theme_minimal() ggAcf(pot_ts) + labs(title = &quot;ACF del precio promedio (diario)&quot;) 2.1.2 Promedios moviles (evidencia de suavizado) pot_ma &lt;- potatored %&gt;% mutate( ma7 = slide_dbl(Average, mean, .before = 6, .complete = TRUE), ma30 = slide_dbl(Average, mean, .before = 29, .complete = TRUE) ) ggplot(pot_ma, aes(Date, Average)) + geom_line(linewidth = 0.5, alpha = 0.6) + geom_line(aes(y = ma7), linewidth = 0.8) + geom_line(aes(y = ma30), linewidth = 0.9) + labs(title = &quot;Serie y promedios moviles (7 y 30 dias)&quot;, x = &quot;Fecha&quot;, y = &quot;Precio promedio&quot;) + theme_minimal() 2.1.3 Rezagos (lags) y dependencia temporal pot_lags &lt;- potatored %&gt;% mutate( lag1 = dplyr::lag(Average, 1), lag7 = dplyr::lag(Average, 7), lag30 = dplyr::lag(Average, 30) ) # Scatter y_t vs y_{t-1} ggplot(pot_lags, aes(lag1, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 1 (y_t vs y_{t-1})&quot;, x = &quot;y_{t-1}&quot;, y = &quot;y_t&quot;) # Scatter y_t vs y_{t-7} ggplot(pot_lags, aes(lag7, Average)) + geom_point(alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, linewidth = 0.7) + theme_minimal() + labs(title = &quot;Scatter rezago 7 (aprox. semanal)&quot;, x = &quot;y_{t-7}&quot;, y = &quot;y_t&quot;) # ACF/PACF (serie regularizada) ggAcf(pot_ts) + labs(title = &quot;ACF precio promedio (diario)&quot;) ggPacf(pot_ts) + labs(title = &quot;PACF precio promedio (diario)&quot;) 2.1.4 Estacionalidad (descomposicion STL) fit_stl &lt;- stl(na.interp(pot_ts), s.window = &quot;periodic&quot;, robust = TRUE) autoplot(fit_stl) + labs(title = &quot;STL precio promedio&quot;) El análisis de la serie temporal del precio promedio diario de Potato Red permitió evidenciar comportamientos consistentes con los fenómenos propios de los productos agrícolas de consumo masivo. En primer lugar, los gráficos de tendencia y promedios móviles muestran que los precios presentan fluctuaciones periódicas pero con una ligera tendencia creciente en el largo plazo. El promedio móvil de 7 días suaviza las variaciones diarias y deja entrever ciclos semanales asociados a la oferta en el mercado, mientras que el promedio de 30 días resalta un patrón más estructural que apunta a incrementos graduales, posiblemente relacionados con factores estacionales como la disponibilidad de cosecha o la variación de costos logísticos. El estudio de rezagos (lag 1, lag 7 y lag 30) refuerza esta observación: las gráficas de dispersión muestran una clara autocorrelación positiva, especialmente para rezagos cortos, indicando que los precios actuales dependen directamente de los valores recientes. Este comportamiento sugiere persistencia temporal: cuando los precios aumentan o disminuyen, tienden a mantener esa dirección durante varios días, lo cual es característico de mercados donde la información y las condiciones de oferta no cambian abruptamente. La función de autocorrelación (ACF) confirma esta dependencia temporal, con correlaciones significativas en los primeros rezagos que luego disminuyen de forma progresiva. Esto demuestra que la serie no sigue un comportamiento completamente aleatorio, sino que existen patrones repetitivos en el tiempo. La descomposición STL separó la serie en sus componentes de tendencia, estacionalidad y residuo. Los resultados muestran una estacionalidad marcada con ciclos anuales definidos: los precios tienden a elevarse en ciertas épocas del año y disminuir en otras, reflejando los periodos de cosecha y escasez. La tendencia general es estable con una leve inclinación al alza, mientras que los residuos mantienen una magnitud baja y no presentan patrones visibles, lo que indica que gran parte de la variabilidad del precio está explicada por la tendencia y la estacionalidad, sin presencia de choques exógenos significativos. En conjunto, estos hallazgos evidencian que la serie del precio promedio de Potato Red posee un comportamiento no estacionario, con una tendencia creciente y estacionalidad recurrente, pero sin irregularidades fuertes. El patrón identificado sugiere que los precios pueden modelarse de forma confiable mediante técnicas de suavizado exponencial o modelos ARIMA estacionales, una vez que se realicen las transformaciones necesarias para estabilizar la media y la varianza. En términos prácticos, los resultados reflejan que el mercado analizado responde a ciclos previsibles, lo cual facilita la planificación de precios, abastecimiento y estrategias de comercialización. 2.1.5 Estacionariedad y diferenciación Introducción En esta segunda parte se busca analizar si la serie de tiempo seleccionada (Potato Red) cumple con el supuesto de estacionariedad. Una serie estacionaria es aquella cuya media y varianza permanecen constantes en el tiempo. En caso de que no sea estacionaria, se aplicarán procedimientos de diferenciación # o transformación para estabilizar la tendencia y la variabilidad. # Usaremos una version &quot;limpia&quot; de la serie via interpolacion lineal base R, partimos de &#39;potatored&#39; (data.frame terminado) y/o de &#39;pot_ts&#39; (ts original) y &lt;- as.numeric(pot_ts) if (anyNA(y)) { idx_ok &lt;- which(!is.na(y)) y_interp &lt;- approx(x = idx_ok, y = y[idx_ok], xout = seq_along(y))$y } else { y_interp &lt;- y} pot_ts_clean &lt;- ts( y_interp, start = start(pot_ts), frequency = frequency(pot_ts) ) 2.1.6 Verificación de estacionariedad (ADF Test) # Prueba de raíz unitaria de Dickey-Fuller aumentada adf_result &lt;- adf.test(pot_ts_clean) adf_result ## ## Augmented Dickey-Fuller Test ## ## data: pot_ts_clean ## Dickey-Fuller = -3.0587, Lag order = 14, p-value = 0.1301 ## alternative hypothesis: stationary # al tener en el ADF inicial: p = 0.1301 → se concluye que es no estacionaria al nive, por lo cual procedemos con transformacion y diferenciacion en escalones # Serie base a usar en esta etapa y verificamos que no tenga na ni valores negativos y0 &lt;- pot_ts_clean sum(is.na(y0)) ## [1] 0 all(y0&gt;0) ## [1] TRUE y_log &lt;- log(y0) range(y0, na.rm = TRUE); range(y_log, na.rm = TRUE) # solo para verificar el cambio de escala ## [1] 15.0 113.5 ## [1] 2.708050 4.731803 adf_log &lt;- adf.test(y_log) adf_log$p.value ## [1] 0.1322035 La transformación logarítmica ayudó a homogeneizar la variabilidad, pero no eliminó la tendencia ni la dependencia temporal. La serie transformada sigue teniendo raíz unitaria, por lo que pasamos a una diferenciacion de primer orden (d=1) sobre la serie logaritmica y volvemos a probar estacionariedad. y_diff1 &lt;- diff(y_log, differences = 1) adf_diff1 &lt;- tseries::adf.test(na.omit(y_diff1)) adf_diff1$p.value ## [1] 0.01 con este resultado podemos concluir que: La serie original no era estacionaria (p = 0.1301). La serie logarítmica tampoco lo fue (p = 0.1322), aunque esa transformación ayudó a estabilizar la varianza Al aplicar una diferencia de primer orden sobre la serie logarítmica, la prueba ADF arrojó p = 0.01, es decir &lt; 0.05, por lo tanto sí es estacionaria. 2.1.7 Interpretacion Luego de aplicar la transformación logarítmica, la serie mantuvo la misma tendencia general, por lo que no se logró estacionariedad. Sin embargo, al diferenciarla una vez (d = 1), la prueba de Dickey–Fuller aumentada mostró un p-valor de 0.01, lo que indica que se rechaza la hipótesis nula de raíz unitaria. En consecuencia, la serie diferenciada es estacionaria. Este resultado implica que la tendencia determinista fue eliminada mediante la primera diferencia, estabilizando la media a lo largo del tiempo. Por otro lado, la transformación logarítmica permitió controlar la heterocedasticidad, de modo que las fluctuaciones de la serie ahora son de magnitud comparable. La combinación de ambos pasos —logaritmo y diferencia de primer orden— produce una serie adecuada para modelar mediante métodos lineales, como los modelos ARIMA o SARIMA. Visualmente, la serie diferenciada oscila alrededor de cero y las funciones de autocorrelación (ACF y PACF) se estabilizan rápidamente, lo que refuerza la evidencia de estacionariedad. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
