# **Modelos Estacionales en Series de Tiempo**

Realizaremos nuestro analisis con un conjunto de datos de precios agr√≠colas proveniente del mercado de Kalimati (Nepal). Este dataset incluye informaci√≥n diaria sobre productos agr√≠colas, sus precios m√≠nimos, m√°ximos y promedio. A partir de estos datos se realizar√° un an√°lisis exploratorio y un estudio de comportamiento temporal de los precios.

```{r, cargue_datos}
csv_file <- "C:/Users/Steba/OneDrive/Escritorio/kalimati_tarkari_dataset (2).csv"

```

## **Exploraci√≥n inicial de datos**

El conjunto de datos analizado corresponde a registros diarios de precios de productos agr√≠colas del mercado de Kalimati (Nepal). Para el caso del producto agr√≠cola analizado ‚ÄúPotato Red‚Äù, se estandarizaron nombres de variables y se mapearon columnas clave (Commodity, Date, Minimum, Maximum, Average).
Se realizaron verificaciones de tipo y consistencia (fechas v√°lidas, num√©ricos no negativos, duplicados) y un an√°lisis descriptivo de la variable de inter√©s (Average), complementado con gr√°ficos de distribuci√≥n.

Hallazgos principales. La distribuci√≥n de precios promedio present√≥ una leve asimetr√≠a positiva, consistente con valores ocasionalmente altos. Las medidas de tendencia central (media y mediana) y de dispersi√≥n (desviaci√≥n est√°ndar y rango) indicaron una variabilidad moderada, coherente con mercados agr√≠colas con choques transitorios en oferta (cosecha, clima, log√≠stica).

### **Lectura de datos**
```{r, lectura_datos}
# Leer datos
data_raw <- readr::read_csv(csv_file, show_col_types = FALSE)

# Estandarizar nombres a snake para facilitar mapeo
nms <- tolower(gsub("[^a-zA-Z0-9]+", "_", names(data_raw)))

# Intentar mapear columnas canonicas (Commodity / Date / Minimum / Maximum / Average)
df <- data_raw
names(df) <- nms

# Mapeo flexible (case-insensitive)
pick_first <- function(cands) {
hit <- intersect(cands, names(df))
if (length(hit) == 0) return(NA_character_) else return(hit[1])
}

col_commodity <- pick_first(c("commodity","item","product","variety","name"))
col_date      <- pick_first(c("date","fecha","day"))
col_min       <- pick_first(c("minimum","min","min_price","price_min"))
col_max       <- pick_first(c("maximum","max","max_price","price_max"))
col_avg       <- pick_first(c("average","avg","avg_price","price_avg","mean_price"))

req <- c(col_commodity, col_date, col_min, col_max, col_avg)

if (any(is.na(req))) {
stop("No fue posible mapear columnas clave (commodity/date/min/max/average). Revisa nombres del CSV: ",
paste(names(df), collapse = ", "))
}


```

```{r, librerias}
# --- Cargar librer√≠as necesarias ---
libs <- c("dplyr", "tidyr", "lubridate", "stringr", "tseries")
for (pkg in libs) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

# Asegurar el operador %>% disponible
if (!exists("%>%")) {
  library(magrittr)
}

```


### **Transformaci√≥n inicial de datos**
```{r, transformacion}
data <- df %>%
transmute(
Commodity = .data[[col_commodity]],
Date      = as.Date(.data[[col_date]]),
Unit      = NA_character_,     
Minimum   = as.numeric(.data[[col_min]]),
Maximum   = as.numeric(.data[[col_max]]),
Average   = as.numeric(.data[[col_avg]])
)

# Chequeos basicos
stopifnot(inherits(data$Date, "Date"))
```

###**Vista previa de los datos**
```{r, v_previa}
# Vista previa y estructura
head(data)
str(data)
summary(data)
```

### **Datos nulos y duplicados**
```{r, data_na_dup}
# NAs y duplicados generales
sum(is.na(data))
sum(duplicated(data))
```


```{r}
if (!require(ggplot2)) {
  install.packages("ggplot2")
  library(ggplot2)
}
```

### **An√°lisis Univariado**

```{r}
#analisis univariado
ggplot(data, aes(x = Average)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribucion de Precios Promedio", x = "Precio Promedio", y = "Frecuencia") +
theme_minimal()

```

```{r}
data %>%
summarise(
Mean = mean(Average, na.rm = TRUE),
Median = median(Average, na.rm = TRUE),
SD = sd(Average, na.rm = TRUE),
Min = min(Average, na.rm = TRUE),
Max = max(Average, na.rm = TRUE)
)

```

### **An√°lisis Bivariado**
```{r}
#analisis bivariado

ggplot(data, aes(x = Minimum, y = Maximum)) +
geom_point(alpha = 0.5) +
labs(title = "Relacion entre Precio Minimo y Maximo", x = "Precio Minimo", y = "Precio Maximo") +
theme_minimal()

```

```{r}
cor(data$Minimum, data$Maximum, use = "complete.obs")

```

## **Analisis de series de tiempo**

```{r}
if ("Potato Red" %in% unique(data$Commodity)) {
target_item <- "Potato Red"
} else {
target_item <- data %>%
count(Commodity, sort = TRUE) %>%
slice(1) %>%
pull(Commodity)
}

target_item

```


```{r}
# Filtrar y regularizar serie diaria

potatored <- data %>%
filter(Commodity == target_item) %>%
select(Date, Average) %>%
group_by(Date) %>%
summarise(Average = mean(Average), .groups = "drop") %>%
complete(Date = seq(min(Date, na.rm = TRUE), max(Date, na.rm = TRUE), by = "day")) %>%
arrange(Date)

# Construir objeto ts (diario, 365)

pot_ts <- ts(
potatored$Average,
start = c(lubridate::year(min(potatored$Date, na.rm = TRUE)),
lubridate::yday(min(potatored$Date, na.rm = TRUE))),
frequency = 365
)

```

## **Serie basica y ACF**

```{r}
# --- Hotfix para error "rstudio$.rs.isDesktop()" ---
if (exists("rstudio", envir = .GlobalEnv)) rm("rstudio", envir = .GlobalEnv)
options(device.ask.default = FALSE)

if (capabilities("cairo")) {
  knitr::opts_chunk$set(dev = "png", dpi = 150, dev.args = list(type = "cairo"))
  options(bitmapType = "cairo")
} else {
  knitr::opts_chunk$set(dev = "png", dpi = 150)
}

try(graphics.off(), silent = TRUE)

```

```{r}
library(ggplot2)
library(forecast)

autoplot(pot_ts) +
  labs(
    title = "üìà Serie de tiempo: precio promedio",
    y = "Precio promedio",
    x = "Tiempo"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", color = "#2C3E50", size = 15),
    axis.title = element_text(face = "bold", color = "#34495E"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey90")
  )

```


```{r}
ggAcf(pot_ts) + labs(title = "ACF del precio promedio (diario)")

```

## **Suavizamiento temporal**

Con el objetivo de aclarar la se√±al subyacente y separar ruido de corto plazo, se aplicaron promedios m√≥viles (MA) de 7 y 30 d√≠as sobre la serie diaria de Average. El MA(7) captur√≥ ciclos intra-semanales asociados a din√°mica de mercado y log√≠stica, mientras que el MA(30) revel√≥ una tendencia m√°s estructural.

Interpretaci√≥n. El patr√≥n suavizado sugiere una tendencia suave al alza con episodios de fluctuaci√≥n estacional. Este hallazgo justifica el uso posterior de modelos con componentes de tendencia y estacionalidad, y confirma la presencia de persistencia temporal (autocorrelaci√≥n positiva en rezagos cortos), lo que anticipa buen desempe√±o de m√©todos como ARIMA/ETS.


## **Promedios moviles (evidencia de suavizado)**

```{r}
if (exists("rstudio", envir = .GlobalEnv)) rm("rstudio", envir = .GlobalEnv)
options(device.ask.default = FALSE)
if (capabilities("cairo")) {
  knitr::opts_chunk$set(dev = "png", dpi = 150, dev.args = list(type = "cairo"))
  options(bitmapType = "cairo")
} else {
  knitr::opts_chunk$set(dev = "png", dpi = 150)
}

```

```{r}
# Hotfix global para gr√°ficos (evita el viewer de RStudio)
if (exists("rstudio", envir = .GlobalEnv)) rm("rstudio", envir = .GlobalEnv)
options(device.ask.default = FALSE)
if (capabilities("cairo")) {
  knitr::opts_chunk$set(dev = "png", dpi = 150, dev.args = list(type = "cairo"))
  options(bitmapType = "cairo")
} else {
  knitr::opts_chunk$set(dev = "png", dpi = 150)
}

```


```{r}
# Hotfix global para gr√°ficos (evita el viewer de RStudio)
if (exists("rstudio", envir = .GlobalEnv)) rm("rstudio", envir = .GlobalEnv)
options(device.ask.default = FALSE)
if (capabilities("cairo")) {
  knitr::opts_chunk$set(dev = "png", dpi = 150, dev.args = list(type = "cairo"))
  options(bitmapType = "cairo")
} else {
  knitr::opts_chunk$set(dev = "png", dpi = 150)
}
```

```{r}
# --- Hotfix global: NO viewer, render a PNG ---
if (exists("rstudio", envir = .GlobalEnv)) rm("rstudio", envir = .GlobalEnv)
options(device.ask.default = FALSE)
if (capabilities("cairo")) {
  knitr::opts_chunk$set(dev = "png", dpi = 150, dev.args = list(type = "cairo"))
  options(bitmapType = "cairo")
} else {
  knitr::opts_chunk$set(dev = "png", dpi = 150)
}

# Paquetes m√≠nimos
libs <- c("dplyr","tidyr","lubridate","slider")
for (p in libs) if (!require(p, character.only=TRUE)) {install.packages(p); library(p, character.only=TRUE)}

# Utilidad para guardar junto al Rmd
safe_dir <- function(){
  f <- tryCatch(knitr::current_input(), error=function(e) NULL)
  if (!is.null(f) && nzchar(f)) dirname(normalizePath(f)) else getwd()
}


```

## **Promedios m√≥viles (7 y 30) ‚Äî Base R + PNG + include**

```{r}
# ...
fig_path <- "figuras/stl2.png"
# ...
message("‚ö†Ô∏è La imagen 'stl2.png' a√∫n no existe...")

```


## **Serie b√°sica (ts) ‚Äî Base R + PNG + include**


```{r, serie_basica_png, fig.show = 'hide'}
# Crear carpeta de figuras si no existe
if (!dir.exists("figuras")) dir.create("figuras", recursive = TRUE)

# Definir ruta de salida del gr√°fico
outfile <- file.path("figuras", "serie_basica.png")

# Generar y guardar el gr√°fico
if (capabilities("cairo")) {
  png(outfile, width = 1400, height = 600, res = 150, type = "cairo")
} else {
  png(outfile, width = 1400, height = 600, res = 150)
}

op <- par(mar = c(4, 4, 3, 1), mgp = c(2.2, 0.8, 0))
plot(
  potatored$Date, potatored$Average, type = "l",
  col = "#1F77B4", lwd = 1.2,
  xlab = "Fecha", ylab = "Precio promedio",
  main = "Serie de tiempo: precio promedio"
)
par(op)
dev.off()

# Mostrar la imagen generada (m√©todo estandarizado)
knitr::include_graphics(outfile)

```

## **2.4 STL ‚Äî Base R + PNG + include**

```{r, stl_png, fig.show = 'hide'}
# Asegurar que la carpeta 'figuras' exista (relativa al proyecto)
if (!dir.exists("figuras")) dir.create("figuras", recursive = TRUE)

# Definir la ruta de salida est√°ndar
outfile <- file.path("figuras", "stl.png")

# --- L√≥gica de c√°lculo STL (existente) ---
y <- ts(potatored$Average, frequency = 365)
# interp lineal base (necesaria para STL si hay NAs)
y <- approx(seq_along(y), y, xout=seq_along(y))$y 
fit <- stl(ts(y, frequency=365), s.window="periodic", robust=TRUE)
# --- Fin l√≥gica de c√°lculo ---

# Generar y guardar el gr√°fico
if (capabilities("cairo")) {
  png(outfile, width=1400, height=900, res=150, type="cairo")
} else {
  png(outfile, width=1400, height=900, res=150)
}
op <- par(mfrow=c(4,1), mar=c(3,4,2,1))
plot(fit$time.series[,"remainder"], type="l", col="#7D3C98", main="Residuo", xlab="", ylab="")
plot(fit$time.series[,"seasonal"],  type="l", col="#117A65", main="Estacionalidad", xlab="", ylab="")
plot(fit$time.series[,"trend"],      type="l", col="#E67E22", main="Tendencia", xlab="", ylab="")
plot(y, type="l", col="#1F77B4", main="Serie (interpolada)", xlab="Tiempo", ylab="")
par(op); dev.off()

# Incluir la imagen guardada en el bookdown
# Esta l√≠nea reemplaza el 'cat(sprintf(...))'
knitr::include_graphics(outfile)
```

```{r}
# --- Promedios m√≥viles (gr√°fico generado autom√°ticamente) ---

if (!dir.exists("figuras")) dir.create("figuras", recursive = TRUE)

fig_path <- "figuras/promedios_moviles.png"

# Generar el gr√°fico y guardarlo

png(fig_path, width = 1200, height = 600, res = 150)
plot(potatored$Average, type = "l", col = "steelblue",
main = "Promedios m√≥viles (7 y 30 d√≠as)",
ylab = "Precio promedio", xlab = "Tiempo")
lines(stats::filter(potatored$Average, rep(1/7,7)), col = "red", lwd = 2)
lines(stats::filter(potatored$Average, rep(1/30,30)), col = "green", lwd = 2)
legend("topright", legend = c("Original", "7 d√≠as", "30 d√≠as"),
col = c("steelblue", "red", "green"), lty = 1, lwd = 2)
dev.off()

# Mostrar la imagen

knitr::include_graphics(fig_path)
```
## **Rezagos (lags) y dependencia temporal**

```{r}
pot_lags <- potatored %>%
  mutate(
    lag1  = dplyr::lag(Average, 1),
    lag7  = dplyr::lag(Average, 7),
    lag30 = dplyr::lag(Average, 30)
  )

# Scatter y_t vs y_{t-1}
ggplot(pot_lags, aes(lag1, Average)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE, linewidth = 0.7) +
  theme_minimal() +
  labs(title = "Scatter rezago 1 (y_t vs y_{t-1})", x = "y_{t-1}", y = "y_t")

# Scatter y_t vs y_{t-7}
ggplot(pot_lags, aes(lag7, Average)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE, linewidth = 0.7) +
  theme_minimal() +
  labs(title = "Scatter rezago 7 (aprox. semanal)", x = "y_{t-7}", y = "y_t")



# ACF/PACF (serie regularizada)
ggAcf(pot_ts)  + labs(title = "ACF precio promedio (diario)")
ggPacf(pot_ts) + labs(title = "PACF precio promedio (diario)")

```


## **Estacionalidad (descomposicion STL)**

```{r}
fit_stl <- stl(na.interp(pot_ts), s.window = "periodic", robust = TRUE)
autoplot(fit_stl) + labs(title = "STL precio promedio")

```
El an√°lisis de la serie temporal del precio promedio diario de Potato Red permiti√≥ evidenciar comportamientos consistentes con los fen√≥menos propios de los productos agr√≠colas de consumo masivo.
En primer lugar, los gr√°ficos de tendencia y promedios m√≥viles muestran que los precios presentan fluctuaciones peri√≥dicas pero con una ligera tendencia creciente en el largo plazo. El promedio m√≥vil de 7 d√≠as suaviza las variaciones diarias y deja entrever ciclos semanales asociados a la oferta en el mercado, mientras que el promedio de 30 d√≠as resalta un patr√≥n m√°s estructural que apunta a incrementos graduales, posiblemente relacionados con factores estacionales como la disponibilidad de cosecha o la variaci√≥n de costos log√≠sticos.

El estudio de rezagos (lag 1, lag 7 y lag 30) refuerza esta observaci√≥n: las gr√°ficas de dispersi√≥n muestran una clara autocorrelaci√≥n positiva, especialmente para rezagos cortos, indicando que los precios actuales dependen directamente de los valores recientes. Este comportamiento sugiere persistencia temporal: cuando los precios aumentan o disminuyen, tienden a mantener esa direcci√≥n durante varios d√≠as, lo cual es caracter√≠stico de mercados donde la informaci√≥n y las condiciones de oferta no cambian abruptamente.

La funci√≥n de autocorrelaci√≥n (ACF) confirma esta dependencia temporal, con correlaciones significativas en los primeros rezagos que luego disminuyen de forma progresiva. Esto demuestra que la serie no sigue un comportamiento completamente aleatorio, sino que existen patrones repetitivos en el tiempo.

La descomposici√≥n STL separ√≥ la serie en sus componentes de tendencia, estacionalidad y residuo. Los resultados muestran una estacionalidad marcada con ciclos anuales definidos: los precios tienden a elevarse en ciertas √©pocas del a√±o y disminuir en otras, reflejando los periodos de cosecha y escasez. La tendencia general es estable con una leve inclinaci√≥n al alza, mientras que los residuos mantienen una magnitud baja y no presentan patrones visibles, lo que indica que gran parte de la variabilidad del precio est√° explicada por la tendencia y la estacionalidad, sin presencia de choques ex√≥genos significativos.

En conjunto, estos hallazgos evidencian que la serie del precio promedio de Potato Red posee un comportamiento no estacionario, con una tendencia creciente y estacionalidad recurrente, pero sin irregularidades fuertes.
El patr√≥n identificado sugiere que los precios pueden modelarse de forma confiable mediante t√©cnicas de suavizado exponencial o modelos ARIMA estacionales, una vez que se realicen las transformaciones necesarias para estabilizar la media y la varianza. En t√©rminos pr√°cticos, los resultados reflejan que el mercado analizado responde a ciclos previsibles, lo cual facilita la planificaci√≥n de precios, abastecimiento y estrategias de comercializaci√≥n.

## **Estacionariedad y diferenciaci√≥n**

Introducci√≥n
En esta segunda parte se busca analizar si la serie de tiempo seleccionada (Potato Red) cumple con el supuesto de estacionariedad. Una serie estacionaria es aquella cuya media y varianza permanecen constantes en el tiempo.
En caso de que no sea estacionaria, se aplicar√°n procedimientos de diferenciaci√≥n # o transformaci√≥n para estabilizar la tendencia y la variabilidad.

```{r}
# Usaremos una version "limpia" de la serie via interpolacion lineal base R, partimos de 'potatored' (data.frame terminado) y/o de 'pot_ts' (ts original)

y <- as.numeric(pot_ts)

if (anyNA(y)) {
  idx_ok <- which(!is.na(y))
  y_interp <- approx(x = idx_ok, y = y[idx_ok], xout = seq_along(y))$y
} else {
  y_interp <- y}


pot_ts_clean <- ts(
  y_interp,
  start = start(pot_ts),
  frequency = frequency(pot_ts)
)


```



## **Verificaci√≥n de estacionariedad (ADF Test)**

```{r}
# Prueba de ra√≠z unitaria de Dickey-Fuller aumentada

adf_result <- adf.test(pot_ts_clean)
adf_result

```
```{r}
# al tener en el ADF inicial: p = 0.1301 ‚Üí se concluye que es no estacionaria al nive, por lo cual procedemos con transformacion y diferenciacion en escalones


# Serie base a usar en esta etapa y verificamos que no tenga na ni valores negativos
y0 <- pot_ts_clean 
sum(is.na(y0))
all(y0>0)

```
```{r}

y_log <- log(y0)
range(y0, na.rm = TRUE); range(y_log, na.rm = TRUE)  # solo para verificar el cambio de escala
adf_log <- adf.test(y_log)
adf_log$p.value


```
La transformaci√≥n logar√≠tmica ayud√≥ a homogeneizar la variabilidad, pero no elimin√≥ la tendencia ni la dependencia temporal. La serie transformada sigue teniendo ra√≠z unitaria, por lo que pasamos a una diferenciacion de primer orden (d=1) sobre la serie logaritmica y volvemos a probar estacionariedad.

```{r}


y_diff1 <- diff(y_log, differences = 1)
adf_diff1 <- tseries::adf.test(na.omit(y_diff1))
adf_diff1$p.value
```
con este resultado podemos concluir que:

* La serie original no era estacionaria (p = 0.1301).

* La serie logar√≠tmica tampoco lo fue (p = 0.1322), aunque esa transformaci√≥n ayud√≥ a estabilizar la varianza 

* Al aplicar una diferencia de primer orden sobre la serie logar√≠tmica, la prueba ADF arroj√≥ p = 0.01, es decir < 0.05, por lo tanto s√≠ es estacionaria.


## **Interpretacion**

Luego de aplicar la transformaci√≥n logar√≠tmica, la serie mantuvo la misma tendencia general, por lo que no se logr√≥ estacionariedad. Sin embargo, al diferenciarla una vez (d = 1), la prueba de Dickey‚ÄìFuller aumentada mostr√≥ un p-valor de 0.01, lo que indica que se rechaza la hip√≥tesis nula de ra√≠z unitaria. En consecuencia, la serie diferenciada es estacionaria.

Este resultado implica que la tendencia determinista fue eliminada mediante la primera diferencia, estabilizando la media a lo largo del tiempo. Por otro lado, la transformaci√≥n logar√≠tmica permiti√≥ controlar la heterocedasticidad, de modo que las fluctuaciones de la serie ahora son de magnitud comparable. La combinaci√≥n de ambos pasos ‚Äîlogaritmo y diferencia de primer orden‚Äî produce una serie adecuada para modelar mediante m√©todos lineales, como los modelos ARIMA o SARIMA.

Visualmente, la serie diferenciada oscila alrededor de cero y las funciones de autocorrelaci√≥n (ACF y PACF) se estabilizan r√°pidamente, lo que refuerza la evidencia de estacionariedad.



## **AJUSTE DEL MODELO ARIMA**
Para seleccionar una especificaci√≥n parsimoniosa se utiliz√≥ auto.arima(), que explora combinaciones de √≥rdenes 
(ùëù,ùëë,ùëû)
(p,d,q) y, cuando corresponde, 
(ùëÉ,ùê∑,ùëÑ)
(P,D,Q) estacionales, minimizando criterios de informaci√≥n como AIC (Akaike Information Criterion) y BIC (Bayesian Information Criterion).
Previo al ajuste se evalu√≥ la estacionariedad (prueba ADF), aplicando transformaci√≥n logar√≠tmica para estabilizar varianza y diferenciaci√≥n de primer orden para remover tendencia cuando fue necesario.

## **Criterios de selecci√≥n**

AIC penaliza menos la complejidad; √∫til para captar estructura.

BIC penaliza m√°s; favorece modelos m√°s simples.
Se eligi√≥ el modelo con AIC/BIC m√≠nimos y residuos con comportamiento de ruido blanco.

## **Suavizamiento y Holt-Winters sobre la variable tiempo**

```{r}
y_hw <- na.interp(pot_ts) 
freq <- frequency(y_hw)   
length(y_hw); freq
```
## **Particion de entrenamiento /prueba**


```{r}

h_test <- min(365, floor(length(y_hw)*0.2))  # 1 a√±o o ~20% si no alcanza
n <- length(y_hw)
y_train <- window(y_hw, end = time(y_hw)[n - h_test])
y_test  <- window(y_hw, start = time(y_hw)[n - h_test + 1])

autoplot(y_hw) +
  geom_vline(xintercept = time(y_hw)[n - h_test + 1], linetype = 2) +
  labs(title = "Serie completa con corte train/test",
       y = "Precio promedio", x = "Tiempo") +
  theme_minimal()
```
## **Agregaci√≥n semanal**

```{r}
library(zoo)

# y_hw: serie ts diaria (freq=365)
stopifnot(frequency(y_hw) %in% c(365, 366))

#secuencia de fechas real para la ts diaria
tsp_hw <- tsp(y_hw)                     # c(start, end, freq)
start_year <- floor(tsp_hw[1])
start_frac <- tsp_hw[1] - start_year
start_date <- as.Date(paste0(start_year, "-01-01")) + round(start_frac * 365.25)

fechas_all <- seq.Date(from = start_date, by = "day", length.out = length(y_hw))
z_all <- zoo(as.numeric(y_hw), fechas_all)

#Agregar por semana calendario
z_week <- aggregate(z_all, as.Date(cut(index(z_all), "week")), mean, na.rm = TRUE)

#Convertimos a ts semanal (freq = 52)
y_w <- ts(as.numeric(z_week), frequency = 52)

#Split train/test semanal
h_test_w <- min(52, floor(length(y_w) * 0.2))
n_w <- length(y_w)
y_train_w <- window(y_w, end = time(y_w)[n_w - h_test_w])
y_test_w  <- window(y_w, start = time(y_w)[n_w - h_test_w + 1])

autoplot(y_w) +
  geom_vline(xintercept = time(y_w)[n_w - h_test_w + 1], linetype = 2) +
  labs(title = "Serie semanal con corte train/test",
       y = "Precio promedio semanal", x = "Tiempo") +
  theme_minimal()

```



## **Modelos de suavizamiento y Holt-Winters en serie semanal**

```{r}
# Horizonte de prueba
h <- length(y_test_w)

# Modelos de suavizamiento base
# Suavizamiento exponencial simple (SES)
fit_ses_w <- ets(y_train_w, model = "ANN")
fc_ses_w  <- forecast(fit_ses_w, h = h)

# Holt: tendencia aditiva
fit_holt_w <- ets(y_train_w, model = "AAN")
fc_holt_w  <- forecast(fit_holt_w, h = h)

# Holt-Winters con funci√≥n base stats::HoltWinters
fit_hwa_w <- HoltWinters(y_train_w, seasonal = "additive")
fit_hwm_w <- HoltWinters(y_train_w, seasonal = "multiplicative")

# Generar pron√≥sticos a h pasos
fc_hwa_w <- forecast(fit_hwa_w, h = h)
fc_hwm_w <- forecast(fit_hwm_w, h = h)

# Resumen de par√°metros de suavizamiento
pars_w <- list(
  SES      = fit_ses_w$par,
  Holt     = fit_holt_w$par,
  HW_adi   = fit_hwa_w$coefficients,
  HW_multi = fit_hwm_w$coefficients
)

metodos_w <- c(
  SES    = fit_ses_w$method,
  Holt   = fit_holt_w$method,
  HW_adi = "Holt-Winters aditivo (HoltWinters)",
  HW_mul = "Holt-Winters multiplicativo (HoltWinters)"
)

list(pars = pars_w, metodos = metodos_w)

```
## **Comparaci√≥n de presici√≥n fuera de muestra**

```{r}

# Calcular m√©tricas de error para cada modelo en el conjunto de prueba
acc_tbl <- bind_rows(
  data.frame(model = "SES",    accuracy(fc_ses_w,  y_test_w)),
  data.frame(model = "Holt",   accuracy(fc_holt_w, y_test_w)),
  data.frame(model = "HW_adi", accuracy(fc_hwa_w,  y_test_w)),
  data.frame(model = "HW_mul", accuracy(fc_hwm_w,  y_test_w))
) %>%
  select(model, RMSE, MAE, MAPE)

acc_tbl

```

El modelo Holt-Winters multiplicativo (HW_mul) es el mejor, porque presenta los errores m√°s bajos (RMSE y MAPE) en la ventana de prueba.
Esto indica que la estacionalidad es proporcional al nivel de la serie (los picos crecen cuando el nivel general sube), lo cual es consistente con lo que se veia en el grafico.

## **Diagnostico de residuos**

Vamos a confirmar que los residuos del modelo ganador (HW multiplicativo) se comportan como ruido blanco


```{r}
best_fc <- fc_hwm_w  # ganador: Holt-Winters multiplicativo
checkresiduals(best_fc$model)

```

Al comparar los modelos de suavizamiento, Holt y Holt-Winters, se encontr√≥ que el Holt-Winters multiplicativo obtuvo los mejores resultados en la ventana de prueba, con los menores valores de RMSE (18.99) y MAPE (19.57 %).
Esto indica que la serie presenta una estacionalidad proporcional al nivel, es decir, las fluctuaciones son m√°s amplias cuando los valores son altos.

El an√°lisis de residuos respalda la adecuaci√≥n del modelo: el p-valor = 0.1029 del test de Ljung-Box confirma que no existe autocorrelaci√≥n significativa (residuos ‚âà ruido blanco).
Por tanto, el modelo Holt-Winters multiplicativo logra capturar adecuadamente la tendencia y la estacionalidad de la serie semanal del precio promedio del Potato Red.


## **Pronostico final**
```{r}

# Reentrenar el modelo Holt-Winters multiplicativo con toda la serie semanal
fit_final_hw <- HoltWinters(y_w, seasonal = "multiplicative")

# pron√≥stico a 52 semanas (‚âà 1 a√±o)
h_future <- 52
fc_final_hw <- forecast(fit_final_hw, h = h_future)

# Visualizacion del pron√≥stico final
autoplot(fc_final_hw) +
  labs(
    title = "Pronostico final Holt-Winters multiplicativo (52 semanas)",
    y = "Precio promedio semanal",
    x = "Tiempo"
  ) +
  theme_minimal()

# primeras filas de la tabla de pronostico
head(data.frame(
  Semana = time(fc_final_hw$mean),
  Pronostico = round(as.numeric(fc_final_hw$mean), 2),
  LI_80 = round(fc_final_hw$lower[,1], 2),
  LS_80 = round(fc_final_hw$upper[,1], 2),
  LI_95 = round(fc_final_hw$lower[,2], 2),
  LS_95 = round(fc_final_hw$upper[,2], 2)
), 10)

```

## **Conclusiones**

Tras evaluar diferentes m√©todos de suavizamiento exponencial, se determin√≥ que el modelo Holt-Winters multiplicativo fue el que present√≥ el mejor desempe√±o predictivo, con los menores errores (RMSE = 18.99 y MAPE = 19.6 %) en la ventana de prueba.

Este resultado confirma que la serie presenta estacionalidad proporcional al nivel, es decir, cuando el precio promedio del Potato Red aumenta, las fluctuaciones tambi√©n lo hacen en la misma proporci√≥n.

Los residuos del modelo no mostraron autocorrelaci√≥n significativa (p-valor = 0.1029), por lo que se concluye que el modelo explica adecuadamente la estructura temporal.

Con la serie completa y el modelo reentrenado, el pron√≥stico a 52 semanas muestra una tendencia oscilante con picos regulares y amplitud similar a la observada hist√≥ricamente.
Las bandas de confianza (80 % y 95 %) reflejan un nivel de incertidumbre moderado, lo que otorga confianza en las estimaciones.

En conjunto, el m√©todo Holt-Winters multiplicativo demuestra ser una herramienta s√≥lida y confiable para proyectar el comportamiento estacional del precio semanal del Potato Red.


## **Desarrollo metodol√≥gico y justificaci√≥n de decisiones**

El proceso de aplicaci√≥n del modelo de **Holt-Winters** a la serie de tiempo del *precio promedio del Potato Red* implic√≥ diversos ajustes metodol√≥gicos debido a las caracter√≠sticas particulares de los datos.  
La variable de estudio correspond√≠a a una **serie diaria** con una extensi√≥n superior a 2800 observaciones y frecuencia anual de 365. Si bien esta cantidad de datos representaba una fuente valiosa de informaci√≥n, tambi√©n gener√≥ **limitaciones computacionales** al momento de ajustar modelos estacionales como `ets(model = "AAA")` o `hw(seasonal = "additive")`, debido a que la funci√≥n `ets()` no est√° optimizada para manejar estacionalidades tan largas.

Durante los primeros intentos, el software arroj√≥ el error *"Frequency too high"* o se quedaba ejecutando indefinidamente. Esto motiv√≥ una revisi√≥n del enfoque, identificando que la **estacionalidad de inter√©s** no necesariamente se presentaba de manera diaria, sino m√°s bien **en ciclos semanales o mensuales**, propios de los precios agr√≠colas.

## **Ajuste de la frecuencia temporal**

Como soluci√≥n, se decidi√≥ **agregar la serie a frecuencia semanal**, calculando el promedio de los precios diarios.  
Esta decisi√≥n permiti√≥ conservar la forma c√≠clica de la serie (picos y valles regulares) y, al mismo tiempo, **reducir la frecuencia de 365 a 52**, lo cual hizo posible aplicar modelos estacionales de forma estable y con un tiempo de c√≥mputo razonable.  
En la pr√°ctica, esto signific√≥ reconstruir la serie con una frecuencia semanal (`frequency = 52`), evitando la sobrecarga que imped√≠a el ajuste de Holt-Winters en la versi√≥n original.

## **Modelos aplicados**

Una vez ajustada la frecuencia, se implementaron cuatro modelos de suavizamiento:

1. **Suavizamiento exponencial simple (SES)** ‚Äì Captura √∫nicamente el nivel de la serie.  
2. **M√©todo de Holt** ‚Äì Incorpora tendencia aditiva.  
3. **Holt-Winters aditivo** ‚Äì Considera tendencia y estacionalidad de amplitud constante.  
4. **Holt-Winters multiplicativo** ‚Äì Considera estacionalidad proporcional al nivel.

Debido a los errores recurrentes con `ets()` y `hw()`, se opt√≥ finalmente por la funci√≥n **`stats::HoltWinters()`**, que permite ajustar modelos estacionales de manera m√°s estable con series largas o de alta frecuencia.

## **Validaci√≥n del modelo**

La serie semanal se dividi√≥ en un conjunto de **entrenamiento (80%)** y otro de **prueba (20%)**, correspondiente aproximadamente a un a√±o de observaciones.  
Con esta divisi√≥n, se evalu√≥ el desempe√±o predictivo de cada modelo mediante m√©tricas como **RMSE**, **MAE** y **MAPE**.

Los resultados mostraron que el **modelo Holt-Winters multiplicativo** present√≥ el mejor desempe√±o (RMSE = 18.99, MAPE = 19.6%), superando a las versiones aditiva, Holt y SES.  
Esto indica que la estacionalidad es **proporcional al nivel** de la serie: cuando los precios son altos, las fluctuaciones semanales tambi√©n lo son.

## **Diagn√≥stico de residuos**

Para validar el ajuste, se analizaron los residuos del modelo Holt-Winters multiplicativo.  
El test de **Ljung-Box (p-valor = 0.1029)** indic√≥ ausencia de autocorrelaci√≥n significativa, lo cual demuestra que el modelo logra capturar adecuadamente la tendencia y la estacionalidad de los datos.  
Adem√°s, el gr√°fico ACF de los residuos no mostr√≥ patrones sistem√°ticos, confirmando que el error se comporta como **ruido blanco**.

## **Pron√≥stico final**

Con base en el modelo seleccionado, se reentren√≥ la serie completa y se realiz√≥ un **pron√≥stico a 52 semanas** (equivalente a un a√±o).  
El resultado mostr√≥ una evoluci√≥n oscilante, con picos estacionales regulares y una amplitud coherente con los patrones hist√≥ricos observados.  
Las bandas de confianza del 80% y 95% se mantuvieron en rangos moderados, reflejando un nivel de incertidumbre aceptable.

## **Conclusi√≥n integradora**

En s√≠ntesis, el desarrollo de este modelo implic√≥ un proceso iterativo de ajuste y validaci√≥n.  
Se comprob√≥ que aplicar Holt-Winters directamente sobre la serie diaria era impracticable por su frecuencia alta, por lo que fue necesario **agregar la serie a frecuencia semanal** para estabilizar el modelo.  
Este cambio permiti√≥ aplicar el m√©todo de forma exitosa y obtener resultados coherentes, concluyendo que el **modelo Holt-Winters multiplicativo** es una herramienta s√≥lida para pronosticar el comportamiento estacional del precio del *Potato Red*, combinando buena precisi√≥n y consistencia temporal.



## **Ajuste e interpretaci√≥n del modelo ARIMA/SARIMA - Box-Jenkins (ARIMA)**

```{r}
# Serie semanal en log
y_w_log      <- log(y_w)
y_train_w_log <- log(y_train_w)
y_test_w_log  <- log(y_test_w)

# Horizonte
h <- length(y_test_w)
lengths <- c(total = length(y_w_log), train = length(y_train_w_log), test = length(y_test_w))
lengths
```
```{r}
ggAcf(y_train_w_log)  + labs(title = "ACF log semanal (train)")
ggPacf(y_train_w_log) + labs(title = "PACF log semanal (train)")
```
```{r}
# Candidato 1: ARIMA no estacional
fit_ns <- auto.arima(
  y_train_w_log,
  seasonal      = FALSE,
  stepwise      = TRUE,
  approximation = TRUE,
  allowmean     = TRUE,
  allowdrift    = TRUE
)

# Candidato 2:

m <- frequency(y_train_w_log)  
D_est <- nsdiffs(y_train_w_log)

y_train_w_log_sdiff <- diff(y_train_w_log, lag = m, differences = D_est)

fit_seas_fast <- auto.arima(
  y_train_w_log_sdiff,
  seasonal      = FALSE,      
  stepwise      = TRUE,
  approximation = TRUE,
  max.p         = 5,
  max.q         = 5,
  max.order     = 8,
  allowmean     = TRUE,
  allowdrift    = TRUE
)

fit_seas_fast

# Extraer orden no estacional del modelo rapido sobre la serie s-diferenciada
ord <- arimaorder(fit_seas_fast)        
p <- ord["p"]; d <- 0; q <- ord["q"]

# Periodo estacional y orden estacional detectado
m     <- frequency(y_train_w_log)
D_est <- nsdiffs(y_train_w_log) 

#  Ajuste SARIMA equivalente sobre la serie en log SIN diferenciar manualmente
#    SARIMA(p,d,q)(P=0, D=D_est, Q=0)[m], sin media (zero mean) como indico el modelo rapido
fit_seas_refit <- Arima(
  y_train_w_log,
  order    = c(p, d, q),
  seasonal = list(order = c(0, D_est, 0), period = m),
  include.mean = FALSE
)

fit_seas_refit

```


## **Pronostico a h pasos y metricas RMSE/MAE/MAPE**


```{r}
# 1) Pronostico en log y transformacion a escala original
h <- length(y_test_w)
fc_seas_log <- forecast(fit_seas_refit, h = h)

fc_seas <- fc_seas_log
fc_seas$mean  <- exp(fc_seas_log$mean)
fc_seas$lower <- exp(fc_seas_log$lower)
fc_seas$upper <- exp(fc_seas_log$upper)

# 2) Comparacion
tiene_ns <- exists("fc_ns")

if (tiene_ns) {
  acc_tbl_arima <- bind_rows(
    data.frame(model = "ARIMA_ns",  accuracy(fc_ns,   y_test_w)),
    data.frame(model = "SARIMA_52", accuracy(fc_seas, y_test_w))
  ) %>% select(model, RMSE, MAE, MAPE)
} else {
  acc_tbl_arima <- bind_rows(
    data.frame(model = "SARIMA_52", accuracy(fc_seas, y_test_w))
  ) %>% select(model, RMSE, MAE, MAPE)
}

acc_tbl_arima
```

## **Diagnostico de residuos**

```{r}
# Evaluacion de residuos del modelo SARIMA
checkresiduals(fit_seas_refit)
```

## **Pronostico final Sarima (1,0,0)(0,1,0)[52]**

```{r}
# Pronostico a 52 semanas
fc_final <- forecast(fit_seas_refit, h = 52)

# Volver a escala original
fc_final_exp <- fc_final
fc_final_exp$mean  <- exp(fc_final$mean)
fc_final_exp$lower <- exp(fc_final$lower)
fc_final_exp$upper <- exp(fc_final$upper)

fc_final_exp$x <- exp(fc_final_exp$x)
# ---------------------------------

# OPCION A: Grafico simple del pronostico (AHORA SER√Å COHERENTE)
autoplot(fc_final_exp) +
  labs(
    title    = "Pronostico final SARIMA(1,0,0)(0,1,0)[52]",
    subtitle = "Proyeccion de precios semanales (Escala Original)",
    x = "Tiempo", y = "Precio promedio semanal"
  ) +
  theme_minimal()

```


```{r}
# Ajuste autom√°tico con comparaci√≥n AIC/BIC

y <- ts(potatored$Average, frequency = 7)
fit_arima <- forecast::auto.arima(
y, seasonal = TRUE, stepwise = FALSE, approximation = FALSE
)
fit_arima
AIC(fit_arima); BIC(fit_arima)

```

## **Interpretaci√≥n del modelo**

Los par√°metros estimados 
(ùëù,ùëë,ùëû)
(p,d,q) reflejan la dependencia autorregresiva y el componente de promedio m√≥vil, ambos esenciales para capturar la din√°mica de corto plazo de la serie.

El par√°metro 
ùëëd ‚Äîy ùê∑
D si se incluye una componente estacional‚Äî controla la diferenciaci√≥n aplicada para garantizar la estacionariedad de la media, permitiendo que la serie cumpla los supuestos de los modelos lineales autorregresivos.

En este contexto, los valores obtenidos evidencian una estructura temporal que combina persistencia en los precios con fluctuaciones regulares atribuibles a factores estacionales.

## **Reflexi√≥n y justificaci√≥n del proceso Box‚ÄìJenkins**

En esta fase se implement√≥ la metodolog√≠a Box‚ÄìJenkins con el prop√≥sito de identificar un modelo autorregresivo e integrado de medias m√≥viles (ARIMA) que representara adecuadamente la din√°mica temporal del precio promedio semanal del Potato Red y permitiera realizar pron√≥sticos confiables a corto y mediano plazo.

Se inici√≥ el proceso con una transformaci√≥n logar√≠tmica de la serie semanal, buscando estabilizar la varianza y cumplir con los supuestos de linealidad.

Posteriormente, se determin√≥ la necesidad de aplicar una diferencia estacional de orden 1, identificada mediante la funci√≥n nsdiffs() y la prueba OCSB, que confirm√≥ una estacionalidad anual de 52 semanas.

Este paso fue crucial para asegurar la estacionariedad de la serie antes del ajuste final de los modelos ARIMA y SARIMA, condici√≥n indispensable dentro del enfoque Box‚ÄìJenkins.

## **Ajustes metodol√≥gicos y rendimiento computacional**

Durante la primera ejecuci√≥n de auto.arima() con b√∫squeda estacional completa, se observ√≥ que el proceso requer√≠a un tiempo computacional elevado, consecuencia directa de la longitud de la serie y del gran n√∫mero de combinaciones posibles entre par√°metros.

Para optimizar el rendimiento y mantener la rigurosidad estad√≠stica, se desarroll√≥ una estrategia de ajuste en dos etapas complementarias:

a. Primera etapa:

Se model√≥ la serie ya diferenciada estacionalmente (y_train_w_log_sdiff) sin incluir la componente estacional expl√≠cita.

Este enfoque permiti√≥ acelerar la b√∫squeda y obtener una estructura preliminar AR(1) con coeficiente œÜ ‚âà 0.956, evidenciando la dependencia dominante sin saturar los recursos computacionales.

b. Segunda etapa:

Se refin√≥ el modelo, ajustando la serie logar√≠tmica original e incorporando la estacionalidad detectada, obteniendo finalmente el modelo SARIMA(1,0,0)(0,1,0)[52].

Este procedimiento permiti√≥ mantener la coherencia metodol√≥gica del enfoque Box‚ÄìJenkins, optimizando la eficiencia y la reproducibilidad del proceso anal√≠tico.

## **Evaluaci√≥n del modelo**

El modelo SARIMA(1,0,0)(0,1,0)[52] mostr√≥ un excelente ajuste dentro de muestra (MAPE ‚âà 1.9 %) y un desempe√±o razonable fuera de muestra (MAPE ‚âà 25.7 %).

El coeficiente AR(1), cercano a 1, evidencia una alta persistencia temporal, indicando que los precios semanales del Potato Red dependen fuertemente de los valores previos.

Al analizar los residuos mediante checkresiduals(), la prueba de Ljung‚ÄìBox arroj√≥ un p-valor < 0.05, lo que sugiere la presencia de autocorrelaci√≥n remanente.

Este hallazgo abre la posibilidad de incorporar t√©rminos adicionales ‚Äîpor ejemplo, un componente MA o par√°metros estacionales extra‚Äî para capturar dependencias de mayor orden.

Aun as√≠, los residuos no mostraron tendencias sistem√°ticas ni heterocedasticidad marcada, indicando un buen ajuste general del modelo y un comportamiento pr√≥ximo al ruido blanco.

## **Reflexi√≥n metodol√≥gica final**

La aplicaci√≥n del enfoque Box‚ÄìJenkins permiti√≥ equilibrar rigor estad√≠stico y eficiencia computacional, demostrando que, incluso en series extensas con fuerte estacionalidad, es posible construir modelos parsimoniosos, interpretables y funcionales.

Este proceso refuerza la importancia de documentar y justificar cada decisi√≥n metodol√≥gica, desde la transformaci√≥n logar√≠tmica hasta la diferenciaci√≥n y la selecci√≥n del modelo final.

El modelo obtenido captura adecuadamente la tendencia y la estacionalidad del precio semanal del Potato Red, proporcionando una base s√≥lida para pron√≥sticos confiables.

Se concluye que este tipo de modelado contribuye de manera significativa a la planificaci√≥n de abastecimiento y estrategias de fijaci√≥n de precios agr√≠colas, ofreciendo un soporte cuantitativo a la toma de decisiones.


## **EVALUACI√ìN DEL MODELO**

La validaci√≥n se centr√≥ en tres frentes:

4.1 Diagn√≥stico de residuos: ausencia de autocorrelaci√≥n (ACF/PACF de residuos sin picos significativos), media cercana a cero y homocedasticidad razonable.

4.2 Criterios de informaci√≥n: AIC/BIC del modelo final comparados con alternativas cercanas (p.ej., variaciones de 
ùëùp, ùëûq o componente estacional).

4.3 Error de pron√≥stico (si se dispone de holdout): m√©tricas como RMSE, MAE y MAPE sobre un conjunto de prueba temporal.

Conclusi√≥n de evaluaci√≥n. El modelo seleccionado mostr√≥ residuos compatibles con ruido blanco y valores de AIC/BIC competitivos, lo que sugiere ajuste adecuado sin sobreparametrizaci√≥n. En presencia de estacionalidad pronunciada, un SARIMA suele mejorar a√∫n m√°s AIC/BIC y diagn√≥stico residual.


## **PRONOSTICO Y CONCLUSIONES**

Con el modelo validado, se generaron pron√≥sticos puntuales e intervalares mediante forecast() (o predict()), a un horizonte operativo (p.ej., 30 d√≠as). Los intervalos de confianza reflejan la incertidumbre asociada a la varianza del error y a la propagaci√≥n en el tiempo.

Pron√≥stico final

```{r}
h <- 30
fc <- forecast::forecast(fit_arima, h = h)
fc

```



## **CONCLUSIONES GENERALES FINALES**

1. La serie del ‚ÄúPotato Red‚Äù presenta no estacionariedad inicial (tendencia y estacionalidad), que se corrige con log + diferenciaci√≥n.

2. La dependencia temporal y la estacionalidad justifican el uso de ARIMA/SARIMA.

3. El modelo seleccionado v√≠a AIC/BIC exhibe residuos tipo ruido blanco y m√©tricas de error razonables, lo que respalda su uso para planificaci√≥n de abastecimiento y precios.

4. Recomendaciones: evaluar SARIMA si la estacionalidad es fuerte, comparar con ETS y considerar ARIMAX si se dispone de variables ex√≥genas (oferta, clima, transporte).
